{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/MarlonGrandy/LSTMMusicGeneration/blob/main/LSTMMusicGenerationPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiAHuMXqtg9k",
    "outputId": "852d71df-402f-4726-8fe6-92872eff82e1"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aPMvatbQ7_C4"
   },
   "outputs": [],
   "source": [
    "# import statements\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from music21 import converter, instrument, note, chord, stream, duration\n",
    "import glob\n",
    "import os\n",
    "from itertools import chain\n",
    "import copy\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers import CuDNNLSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import argmax\n",
    "from fractions import Fraction\n",
    "import gc\n",
    "import random\n",
    "import keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2RBI4UDFDr6A"
   },
   "outputs": [],
   "source": [
    "def data_extractor(directory = \"./midi_files/default_dataset/*.mid\"):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "    Function converts midi files to metadata and appends nested metadata lists into one large list\n",
    "    composed of all the songs in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    directory: String representation of directory where midi files are located\n",
    "\n",
    "    Returns:\n",
    "    list: sequential midi file metadata \n",
    "    \"\"\"\n",
    "    \n",
    "    notes = []\n",
    "    offsets = []\n",
    "    durations = []\n",
    "    for file in glob.glob(directory):\n",
    "        mid = converter.parse(file)\n",
    "        notes_to_parse = None\n",
    "        prev_offset = 0 #taking difference between offsets, not absolute\n",
    "\n",
    "        try:\n",
    "            s2 = instrument.partitionByInstrument(mid) #can be multiple instruments in midi and splits it up, 0 index is piano\n",
    "            notes_to_parse = s2.recurse()\n",
    "\n",
    "\n",
    "        except:\n",
    "            notes_to_parse = mid.flat.notes #gets all the notes you're gonna parse through\n",
    "\n",
    "        for i, element in enumerate(notes_to_parse):\n",
    "            if isinstance(element, note.Note):\n",
    "                notes.append(str(element.pitch))\n",
    "\n",
    "                durations.append(str(element.quarterLength))\n",
    "\n",
    "                offset_dif = float(element.offset - prev_offset)\n",
    "\n",
    "                offsets.append(round(offset_dif, 3)) # rounded off to 3 decimal places\n",
    "                prev_offset = element.offset\n",
    "\n",
    "            elif isinstance(element, chord.Chord):\n",
    "                notes.append(\".\".join(str(n) for n in element.normalOrder)) # chords: all notes joined together by a string ie c.e.g\n",
    "                offset_dif = float(element.offset - prev_offset)\n",
    "\n",
    "                durations.append(str(element.quarterLength))\n",
    "\n",
    "                offsets.append(round(offset_dif, 3))\n",
    "                prev_offset = element.offset\n",
    "\n",
    "    return [notes, offsets, durations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./midi_files/*.mid\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "uM7ofNWWbp4Q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./midi_files/default_dataset/*.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anguyen/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=0, channel=None, data=b'J\\xe4gerlied'>; getting generic Instrument\n",
      "  warnings.warn(\n",
      "/Users/anguyen/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/midi/translate.py:863: TranslateWarning: Unable to determine instrument from <music21.midi.MidiEvent SEQUENCE_TRACK_NAME, track=5, channel=None, data=b'Copyright \\xa9 2010 by Bernd Krueger'>; getting generic Instrument\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "6365042528",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m     data \u001b[39m=\u001b[39m data_extractor()\n\u001b[1;32m      7\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     data \u001b[39m=\u001b[39m data_extractor(user_dir)\n\u001b[1;32m     10\u001b[0m note_data \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m offset_data \u001b[39m=\u001b[39m data[\u001b[39m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn [4], line 17\u001b[0m, in \u001b[0;36mdata_extractor\u001b[0;34m(directory)\u001b[0m\n\u001b[1;32m     15\u001b[0m durations \u001b[39m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(directory):\n\u001b[0;32m---> 17\u001b[0m     mid \u001b[39m=\u001b[39m converter\u001b[39m.\u001b[39;49mparse(file)\n\u001b[1;32m     18\u001b[0m     notes_to_parse \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     prev_offset \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/__init__.py:1297\u001b[0m, in \u001b[0;36mparse\u001b[0;34m(value, forceSource, number, format, **keywords)\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[39mreturn\u001b[39;00m parseData(value, number\u001b[39m=\u001b[39mnumber, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeywords)\n\u001b[1;32m   1295\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mbytes\u001b[39m)\n\u001b[1;32m   1296\u001b[0m       \u001b[39mand\u001b[39;00m _osCanLoad(valueStr)):\n\u001b[0;32m-> 1297\u001b[0m     \u001b[39mreturn\u001b[39;00m parseFile(valueStr, number\u001b[39m=\u001b[39;49mnumber, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m,\n\u001b[1;32m   1298\u001b[0m                      forceSource\u001b[39m=\u001b[39;49mforceSource, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n\u001b[1;32m   1299\u001b[0m \u001b[39melif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mbytes\u001b[39m)\n\u001b[1;32m   1300\u001b[0m       \u001b[39mand\u001b[39;00m _osCanLoad(common\u001b[39m.\u001b[39mcleanpath(valueStr))):\n\u001b[1;32m   1301\u001b[0m     \u001b[39mreturn\u001b[39;00m parseFile(common\u001b[39m.\u001b[39mcleanpath(valueStr), number\u001b[39m=\u001b[39mnumber, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m,\n\u001b[1;32m   1302\u001b[0m                      forceSource\u001b[39m=\u001b[39mforceSource, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkeywords)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/__init__.py:1151\u001b[0m, in \u001b[0;36mparseFile\u001b[0;34m(fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m   1149\u001b[0m v \u001b[39m=\u001b[39m Converter()\n\u001b[1;32m   1150\u001b[0m fp \u001b[39m=\u001b[39m common\u001b[39m.\u001b[39mcleanpath(fp, returnPathlib\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m-> 1151\u001b[0m v\u001b[39m.\u001b[39;49mparseFile(fp, number\u001b[39m=\u001b[39;49mnumber, \u001b[39mformat\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mformat\u001b[39;49m, forceSource\u001b[39m=\u001b[39;49mforceSource, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n\u001b[1;32m   1152\u001b[0m \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mTYPE_CHECKING:\n\u001b[1;32m   1153\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(v\u001b[39m.\u001b[39mstream, (stream\u001b[39m.\u001b[39mScore, stream\u001b[39m.\u001b[39mPart, stream\u001b[39m.\u001b[39mOpus))\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/__init__.py:621\u001b[0m, in \u001b[0;36mConverter.parseFile\u001b[0;34m(self, fp, number, format, forceSource, storePickle, **keywords)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    620\u001b[0m     environLocal\u001b[39m.\u001b[39mprintDebug(\u001b[39m'\u001b[39m\u001b[39mLoading original version\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 621\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparseFileNoPickle(fp, number, \u001b[39mformat\u001b[39;49m, forceSource, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n\u001b[1;32m    622\u001b[0m     \u001b[39mif\u001b[39;00m writePickle \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39mand\u001b[39;00m fpPickle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m storePickle \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[39m# save the stream to disk...\u001b[39;00m\n\u001b[1;32m    624\u001b[0m         environLocal\u001b[39m.\u001b[39mprintDebug(\u001b[39m'\u001b[39m\u001b[39mFreezing Pickle\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/__init__.py:543\u001b[0m, in \u001b[0;36mConverter.parseFileNoPickle\u001b[0;34m(self, fp, number, format, forceSource, **keywords)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubConverter\u001b[39m.\u001b[39mkeywords \u001b[39m=\u001b[39m keywords\n\u001b[1;32m    542\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 543\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubConverter\u001b[39m.\u001b[39;49mparseFile(\n\u001b[1;32m    544\u001b[0m         fp,\n\u001b[1;32m    545\u001b[0m         number\u001b[39m=\u001b[39;49mnumber,\n\u001b[1;32m    546\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords\n\u001b[1;32m    547\u001b[0m     )\n\u001b[1;32m    548\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    549\u001b[0m     \u001b[39mraise\u001b[39;00m ConverterFileException(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFile is not in a correct format: \u001b[39m\u001b[39m{\u001b[39;00mfp\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/subConverters.py:1203\u001b[0m, in \u001b[0;36mConverterMidi.parseFile\u001b[0;34m(self, filePath, number, **keywords)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m   1193\u001b[0m \u001b[39mGet MIDI data from a file path.\u001b[39;00m\n\u001b[1;32m   1194\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1200\u001b[0m \u001b[39min defaults.quantizationQuarterLengthDivisors. (Default: (4, 3)).\u001b[39;00m\n\u001b[1;32m   1201\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmusic21\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmidi\u001b[39;00m \u001b[39mimport\u001b[39;00m translate \u001b[39mas\u001b[39;00m midiTranslate\n\u001b[0;32m-> 1203\u001b[0m midiTranslate\u001b[39m.\u001b[39;49mmidiFilePathToStream(filePath, inputM21\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/midi/translate.py:2705\u001b[0m, in \u001b[0;36mmidiFilePathToStream\u001b[0;34m(filePath, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   2703\u001b[0m mf\u001b[39m.\u001b[39mread()\n\u001b[1;32m   2704\u001b[0m mf\u001b[39m.\u001b[39mclose()\n\u001b[0;32m-> 2705\u001b[0m \u001b[39mreturn\u001b[39;00m midiFileToStream(mf, inputM21\u001b[39m=\u001b[39;49minputM21, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/midi/translate.py:2876\u001b[0m, in \u001b[0;36mmidiFileToStream\u001b[0;34m(mf, inputM21, quantizePost, **keywords)\u001b[0m\n\u001b[1;32m   2872\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions21\u001b[39m.\u001b[39mStreamException(\u001b[39m'\u001b[39m\u001b[39mno tracks are defined in this MIDI file.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2874\u001b[0m \u001b[39m# create a stream for each track\u001b[39;00m\n\u001b[1;32m   2875\u001b[0m \u001b[39m# may need to check if tracks actually have event data\u001b[39;00m\n\u001b[0;32m-> 2876\u001b[0m midiTracksToStreams(mf\u001b[39m.\u001b[39;49mtracks,\n\u001b[1;32m   2877\u001b[0m                     ticksPerQuarter\u001b[39m=\u001b[39;49mmf\u001b[39m.\u001b[39;49mticksPerQuarterNote,\n\u001b[1;32m   2878\u001b[0m                     quantizePost\u001b[39m=\u001b[39;49mquantizePost,\n\u001b[1;32m   2879\u001b[0m                     inputM21\u001b[39m=\u001b[39;49ms,\n\u001b[1;32m   2880\u001b[0m                     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n\u001b[1;32m   2881\u001b[0m \u001b[39m# s._setMidiTracks(mf.tracks, mf.ticksPerQuarterNote)\u001b[39;00m\n\u001b[1;32m   2883\u001b[0m \u001b[39mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/midi/translate.py:2613\u001b[0m, in \u001b[0;36mmidiTracksToStreams\u001b[0;34m(midiTracks, ticksPerQuarter, quantizePost, inputM21, **keywords)\u001b[0m\n\u001b[1;32m   2610\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2611\u001b[0m         streamPart \u001b[39m=\u001b[39m conductorPart\n\u001b[0;32m-> 2613\u001b[0m     midiTrackToStream(mt,\n\u001b[1;32m   2614\u001b[0m                       ticksPerQuarter\u001b[39m=\u001b[39;49mticksPerQuarter,\n\u001b[1;32m   2615\u001b[0m                       quantizePost\u001b[39m=\u001b[39;49mquantizePost,\n\u001b[1;32m   2616\u001b[0m                       inputM21\u001b[39m=\u001b[39;49mstreamPart,\n\u001b[1;32m   2617\u001b[0m                       conductorPart\u001b[39m=\u001b[39;49mconductorPart,\n\u001b[1;32m   2618\u001b[0m                       isFirst\u001b[39m=\u001b[39;49m(mt \u001b[39mis\u001b[39;49;00m firstTrackWithNotes),\n\u001b[1;32m   2619\u001b[0m                       \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n\u001b[1;32m   2621\u001b[0m \u001b[39mreturn\u001b[39;00m s\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/midi/translate.py:2091\u001b[0m, in \u001b[0;36mmidiTrackToStream\u001b[0;34m(mt, ticksPerQuarter, quantizePost, inputM21, conductorPart, isFirst, quarterLengthDivisors, **keywords)\u001b[0m\n\u001b[1;32m   2088\u001b[0m     \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m s\u001b[39m.\u001b[39mgetElementsByClass(stream\u001b[39m.\u001b[39mMeasure):\n\u001b[1;32m   2089\u001b[0m         \u001b[39m# Gaps will be filled by makeRests, below, which now recurses\u001b[39;00m\n\u001b[1;32m   2090\u001b[0m         m\u001b[39m.\u001b[39mmakeVoices(inPlace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fillGaps\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m-> 2091\u001b[0m s\u001b[39m.\u001b[39;49mmakeTies(inPlace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2092\u001b[0m \u001b[39m# always need to fill gaps, as rests are not found in any other way\u001b[39;00m\n\u001b[1;32m   2093\u001b[0m s\u001b[39m.\u001b[39mmakeRests(inPlace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fillGaps\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, timeRangeFromBarDuration\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/stream/base.py:6499\u001b[0m, in \u001b[0;36mStream.makeTies\u001b[0;34m(self, meterStream, inPlace, displayTiedAccidentals, classFilterList)\u001b[0m\n\u001b[1;32m   6487\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmakeTies\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m   6488\u001b[0m              meterStream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   6489\u001b[0m              inPlace\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   6490\u001b[0m              displayTiedAccidentals\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m   6491\u001b[0m              classFilterList\u001b[39m=\u001b[39m(note\u001b[39m.\u001b[39mGeneralNote,),\n\u001b[1;32m   6492\u001b[0m              ):\n\u001b[1;32m   6493\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[1;32m   6494\u001b[0m \u001b[39m    Calls :py:func:`~music21.stream.makeNotation.makeTies`.\u001b[39;00m\n\u001b[1;32m   6495\u001b[0m \n\u001b[1;32m   6496\u001b[0m \u001b[39m    Changed in v.4., inPlace=False by default.\u001b[39;00m\n\u001b[1;32m   6497\u001b[0m \u001b[39m    Added in v.7, `classFilterList`.\u001b[39;00m\n\u001b[1;32m   6498\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m-> 6499\u001b[0m     \u001b[39mreturn\u001b[39;00m makeNotation\u001b[39m.\u001b[39;49mmakeTies(\n\u001b[1;32m   6500\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   6501\u001b[0m         meterStream\u001b[39m=\u001b[39;49mmeterStream,\n\u001b[1;32m   6502\u001b[0m         inPlace\u001b[39m=\u001b[39;49minPlace,\n\u001b[1;32m   6503\u001b[0m         displayTiedAccidentals\u001b[39m=\u001b[39;49mdisplayTiedAccidentals,\n\u001b[1;32m   6504\u001b[0m         classFilterList\u001b[39m=\u001b[39;49mclassFilterList,\n\u001b[1;32m   6505\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/stream/makeNotation.py:1312\u001b[0m, in \u001b[0;36mmakeTies\u001b[0;34m(s, meterStream, inPlace, displayTiedAccidentals, classFilterList)\u001b[0m\n\u001b[1;32m   1307\u001b[0m     dst \u001b[39m=\u001b[39m mNext\n\u001b[1;32m   1309\u001b[0m \u001b[39m# mNext.coreSelfActiveSite(eRemain)\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \u001b[39m# manually set activeSite\u001b[39;00m\n\u001b[1;32m   1311\u001b[0m \u001b[39m# cannot use coreInsert here\u001b[39;00m\n\u001b[0;32m-> 1312\u001b[0m dst\u001b[39m.\u001b[39;49minsert(\u001b[39m0\u001b[39;49m, eRemain)\n\u001b[1;32m   1314\u001b[0m \u001b[39m# we are not sure that this element fits\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m \u001b[39m# completely in the next measure, thus, need to\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m \u001b[39m# continue processing each measure\u001b[39;00m\n\u001b[1;32m   1317\u001b[0m \u001b[39mif\u001b[39;00m mNextAdd:\n\u001b[1;32m   1318\u001b[0m     \u001b[39m# environLocal.printDebug([\u001b[39;00m\n\u001b[1;32m   1319\u001b[0m     \u001b[39m#    'makeTies() inserting mNext into returnObj',\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m     \u001b[39m#    mNext])\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/stream/base.py:2257\u001b[0m, in \u001b[0;36mStream.insert\u001b[0;34m(self, offsetOrItemOrList, itemOrNone, ignoreSort, setActiveSite)\u001b[0m\n\u001b[1;32m   2254\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoreGuardBeforeAddElement(element)\n\u001b[1;32m   2255\u001b[0m \u001b[39m# main insert procedure here\u001b[39;00m\n\u001b[0;32m-> 2257\u001b[0m storeSorted \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoreInsert(offset,\n\u001b[1;32m   2258\u001b[0m                               element,\n\u001b[1;32m   2259\u001b[0m                               ignoreSort\u001b[39m=\u001b[39;49mignoreSort,\n\u001b[1;32m   2260\u001b[0m                               setActiveSite\u001b[39m=\u001b[39;49msetActiveSite)\n\u001b[1;32m   2261\u001b[0m updateIsFlat \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m \u001b[39mif\u001b[39;00m element\u001b[39m.\u001b[39misStream:\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/stream/core.py:111\u001b[0m, in \u001b[0;36mStreamCore.coreInsert\u001b[0;34m(self, offset, element, ignoreSort, setActiveSite)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     highestSortTuple \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_elements[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39msortTuple()\n\u001b[0;32m--> 111\u001b[0m     thisSortTuple \u001b[39m=\u001b[39m element\u001b[39m.\u001b[39;49msortTuple()\u001b[39m.\u001b[39mmodify(offset\u001b[39m=\u001b[39moffset)\n\u001b[1;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m highestSortTuple \u001b[39m<\u001b[39m thisSortTuple:\n\u001b[1;32m    114\u001b[0m         storeSorted \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/base.py:2672\u001b[0m, in \u001b[0;36mMusic21Object.sortTuple\u001b[0;34m(self, useSite, raiseExceptionOnMiss)\u001b[0m\n\u001b[1;32m   2670\u001b[0m     insertIndex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msites\u001b[39m.\u001b[39msiteDict[\u001b[39mid\u001b[39m(useSite)]\u001b[39m.\u001b[39mglobalSiteIndex\n\u001b[1;32m   2671\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactiveSite \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 2672\u001b[0m     insertIndex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msites\u001b[39m.\u001b[39;49msiteDict[\u001b[39mid\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mactiveSite)]\u001b[39m.\u001b[39mglobalSiteIndex\n\u001b[1;32m   2673\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# for None, use this instead of default of -2.\u001b[39;00m\n\u001b[1;32m   2674\u001b[0m     insertIndex \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6365042528"
     ]
    }
   ],
   "source": [
    "user_dir = input(\"Please input directory of files without including file names \") + \"/*.mid\"\n",
    "print(user_dir)\n",
    "data = []\n",
    "\n",
    "if user_dir == \"\":\n",
    "    data = data_extractor()\n",
    "else:\n",
    "    data = data_extractor(user_dir)\n",
    "\n",
    "note_data = data[0]\n",
    "offset_data = data[1]\n",
    "duration_data = data[2]\n",
    "\n",
    "unique_note_number = len(list(set(note_data))) # number of unique notes, length of list\n",
    "unique_notes = sorted(list(set(note_data))) # list of unique notes, set\n",
    "unique_offset_number = len(list(set(offset_data)))\n",
    "unique_offsets = sorted(list(set(offset_data)))\n",
    "unique_duration_number = len(list(set(duration_data)))\n",
    "unique_durations = sorted(list(set(duration_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6417368928"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "FcFLfinnvOHJ"
   },
   "outputs": [],
   "source": [
    "def one_hot_encode(vector, all_values): #one hot encoded vector\n",
    "    encoded_vectors = []\n",
    "    int_to_index = dict((c, i) for i, c in enumerate(all_values)) # create dict, map a note to an index so you can easily find it\n",
    "    for i in vector:\n",
    "        zero = [0] * (len(all_values) - 1) # create list of 0s for each note\n",
    "        zero.insert(int_to_index[i], 1) # where this note is present in the list of 0s, replace with a 1\n",
    "        encoded_vectors.append(zero)\n",
    "\n",
    "    return encoded_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "xuDs9q4Ftunv"
   },
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "\n",
    "# turns one hot back to midi notes\n",
    "def one_hot_decode(vector, all_values):\n",
    "    decoded_vector = []\n",
    "    index_to_int = dict((i, c) for i, c in enumerate(all_values))\n",
    "    decoded_vector.append(index_to_int[argmax(vector)]) # takes the highest value in the vector ie 1 and returns index\n",
    "    return decoded_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "vvLcXr-7vr0j"
   },
   "outputs": [],
   "source": [
    "segment_length = 64 # found ideal segment length of 64\n",
    "# take segement lneght of 64 notes which predicts next note theoretically so need to loop to predict more\n",
    "\n",
    "# can take in note offset or duration data and outputs result for each of them\n",
    "def make_segments(data_array, unique_values, seq_length=segment_length):\n",
    "    input_seq = []\n",
    "    output_seq = []\n",
    "\n",
    "    processed_data = one_hot_encode(data_array, unique_values) #one hot encode the data\n",
    "\n",
    "    for i in range(0, len(processed_data) - seq_length, 1):\n",
    "        input_seq.append([processed_data[i : i + seq_length]]) # add segments of 64\n",
    "        output_seq.append(processed_data[seq_length + i]) # add the next note after 64\n",
    "        # supervised learning: we use notes 0-64 to predict 65 but we know 65\n",
    "\n",
    "    del processed_data\n",
    "    gc.collect()\n",
    "\n",
    "    input_seq = np.reshape( # reshaping into what is required for lstm\n",
    "        input_seq, (len(input_seq), segment_length, len(unique_values)) # input_seq is list of lists, len(input_seq) = total number of segments\n",
    "    )\n",
    "    output_seq = np.array(output_seq)\n",
    "\n",
    "    return input_seq, output_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "utzraCh5bx4M"
   },
   "outputs": [],
   "source": [
    "note_model_data = make_segments(data_array=note_data, unique_values=unique_notes)\n",
    "offset_model_data = make_segments(data_array=offset_data, unique_values=unique_offsets)\n",
    "duration_model_data = make_segments(\n",
    "    data_array=duration_data, unique_values=unique_durations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "XYOpsKKdquwj"
   },
   "outputs": [],
   "source": [
    "X_train_note, X_test_note, y_train_note, y_test_note = train_test_split(\n",
    "    note_model_data[0], note_model_data[1], test_size=0.2 #note_model_data[0] is input and [1] is output sequence, test size = 20% of total data\n",
    ")\n",
    "X_train_off, X_test_off, y_train_off, y_test_off = train_test_split(\n",
    "    offset_model_data[0], offset_model_data[1], test_size=0.2\n",
    ")\n",
    "X_train_dur, X_test_dur, y_train_dur, y_test_dur = train_test_split(\n",
    "    duration_model_data[0], duration_model_data[1], test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fJhKOo-5swc",
    "outputId": "363060c0-31c4-4b0e-b648-25925fce0b24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del note_model_data\n",
    "del offset_model_data\n",
    "del duration_model_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "xlEoPwhuwo1i"
   },
   "outputs": [],
   "source": [
    "# inputs model parameter; 1 lstm and 2 dense layers\n",
    "def make_model(input_shape, output_shape):\n",
    "    model = Sequential()\n",
    "    model.add(CuDNNLSTM(512, input_shape=input_shape, return_sequences=False)) # LSTM layer that can run on GPU\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dense(output_shape, activation=\"softmax\")) #use softmax to return a probability vector of the probability of the next note being a certain note\n",
    "\n",
    "    model.compile( # standard\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=0.001), # slowed down learning rate because model was overfitting in later stages of learning\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "hsMf8cKdb8MF"
   },
   "outputs": [],
   "source": [
    "model_notes = make_model(\n",
    "    input_shape=(segment_length, unique_note_number), output_shape=unique_note_number\n",
    ")\n",
    "model_offsets = make_model(\n",
    "    input_shape=(segment_length, unique_offset_number),\n",
    "    output_shape=unique_offset_number,\n",
    ")\n",
    "model_durations = make_model(\n",
    "    input_shape=(segment_length, unique_duration_number),\n",
    "    output_shape=unique_duration_number,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "0zDE5bAKcNAY"
   },
   "outputs": [],
   "source": [
    "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=2)] # early stopping looks at validation. stops when loss stops decreasing and learning\n",
    "# stops at 2 epochs in a row where loss stops decreasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aQq6PZXycBIB",
    "outputId": "856d560d-7e50-49b7-fc5b-783af2891c30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 20:50:10.887781: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-12-05 20:50:11.373753: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - ETA: 0s - loss: 4.9591 - accuracy: 0.0248"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 20:50:52.102532: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 46s 42ms/step - loss: 4.9591 - accuracy: 0.0248 - val_loss: 4.9309 - val_accuracy: 0.0284\n",
      "Epoch 2/150\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 5.0844 - accuracy: 0.0244 - val_loss: 4.9473 - val_accuracy: 0.0267\n",
      "Epoch 3/150\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 4.9412 - accuracy: 0.0250 - val_loss: 4.9224 - val_accuracy: 0.0284\n",
      "Epoch 4/150\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 4.9221 - accuracy: 0.0263 - val_loss: 4.9227 - val_accuracy: 0.0284\n",
      "Epoch 5/150\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 4.9153 - accuracy: 0.0268 - val_loss: 4.9128 - val_accuracy: 0.0284\n",
      "Epoch 6/150\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 4.9125 - accuracy: 0.0267 - val_loss: 4.9206 - val_accuracy: 0.0284\n",
      "Epoch 7/150\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 4.9105 - accuracy: 0.0274 - val_loss: 4.9187 - val_accuracy: 0.0284\n"
     ]
    }
   ],
   "source": [
    "history_note = model_notes.fit(\n",
    "    X_train_note, y_train_note, epochs=150, validation_split=0.2, callbacks=my_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "eGp9R-18cEbB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 20:55:15.556140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - ETA: 0s - loss: 0.9986 - accuracy: 0.6377"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 20:55:52.469607: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 42s 38ms/step - loss: 0.9986 - accuracy: 0.6377 - val_loss: 0.7999 - val_accuracy: 0.7121\n",
      "Epoch 2/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.7412 - accuracy: 0.7376 - val_loss: 0.7299 - val_accuracy: 0.7473\n",
      "Epoch 3/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.6592 - accuracy: 0.7708 - val_loss: 0.6285 - val_accuracy: 0.7858\n",
      "Epoch 4/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.6015 - accuracy: 0.7926 - val_loss: 0.5883 - val_accuracy: 0.7938\n",
      "Epoch 5/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.5618 - accuracy: 0.8064 - val_loss: 0.5554 - val_accuracy: 0.8162\n",
      "Epoch 6/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.5280 - accuracy: 0.8200 - val_loss: 0.5540 - val_accuracy: 0.8174\n",
      "Epoch 7/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.4974 - accuracy: 0.8310 - val_loss: 0.5356 - val_accuracy: 0.8210\n",
      "Epoch 8/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.4687 - accuracy: 0.8401 - val_loss: 0.5161 - val_accuracy: 0.8304\n",
      "Epoch 9/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.4362 - accuracy: 0.8509 - val_loss: 0.5176 - val_accuracy: 0.8335\n",
      "Epoch 10/150\n",
      "1080/1080 [==============================] - 41s 38ms/step - loss: 0.4074 - accuracy: 0.8603 - val_loss: 0.5265 - val_accuracy: 0.8279\n"
     ]
    }
   ],
   "source": [
    "history_offset = model_offsets.fit(\n",
    "    X_train_off, y_train_off, epochs=150, validation_split=0.2, callbacks=my_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "6RMQVDFH7wsb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 21:02:07.931059: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - ETA: 0s - loss: 1.0376 - accuracy: 0.6988"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 21:02:45.270210: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1080/1080 [==============================] - 43s 39ms/step - loss: 1.0376 - accuracy: 0.6988 - val_loss: 0.9543 - val_accuracy: 0.7170\n",
      "Epoch 2/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.9373 - accuracy: 0.7133 - val_loss: 0.8913 - val_accuracy: 0.7235\n",
      "Epoch 3/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.8769 - accuracy: 0.7270 - val_loss: 0.8255 - val_accuracy: 0.7425\n",
      "Epoch 4/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.8045 - accuracy: 0.7488 - val_loss: 0.7768 - val_accuracy: 0.7616\n",
      "Epoch 5/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.7516 - accuracy: 0.7681 - val_loss: 0.7306 - val_accuracy: 0.7777\n",
      "Epoch 6/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.6980 - accuracy: 0.7872 - val_loss: 0.7053 - val_accuracy: 0.7899\n",
      "Epoch 7/150\n",
      "1080/1080 [==============================] - 45s 42ms/step - loss: 0.6524 - accuracy: 0.7995 - val_loss: 0.6585 - val_accuracy: 0.8031\n",
      "Epoch 8/150\n",
      "1080/1080 [==============================] - 45s 41ms/step - loss: 0.6098 - accuracy: 0.8145 - val_loss: 0.6198 - val_accuracy: 0.8188\n",
      "Epoch 9/150\n",
      "1080/1080 [==============================] - 46s 43ms/step - loss: 0.5631 - accuracy: 0.8280 - val_loss: 0.5968 - val_accuracy: 0.8234\n",
      "Epoch 10/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.5197 - accuracy: 0.8416 - val_loss: 0.5927 - val_accuracy: 0.8321\n",
      "Epoch 11/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.4775 - accuracy: 0.8540 - val_loss: 0.5890 - val_accuracy: 0.8359\n",
      "Epoch 12/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.4389 - accuracy: 0.8660 - val_loss: 0.5802 - val_accuracy: 0.8404\n",
      "Epoch 13/150\n",
      "1080/1080 [==============================] - 43s 40ms/step - loss: 0.4055 - accuracy: 0.8773 - val_loss: 0.5704 - val_accuracy: 0.8456\n",
      "Epoch 14/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.3674 - accuracy: 0.8875 - val_loss: 0.6001 - val_accuracy: 0.8402\n",
      "Epoch 15/150\n",
      "1080/1080 [==============================] - 42s 39ms/step - loss: 0.3405 - accuracy: 0.8952 - val_loss: 0.5907 - val_accuracy: 0.8443\n"
     ]
    }
   ],
   "source": [
    "history_duration = model_durations.fit(\n",
    "    X_train_dur, y_train_dur, epochs=150, validation_split=0.2, callbacks=my_callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "is75YDQUyDxj"
   },
   "outputs": [],
   "source": [
    "# output for model is probability vector which is mapped to note\n",
    "# noramlly take the highest probabilty and that is the note that is next\n",
    "# however, we skew the probabilities by a certain amount so different probabilities will be chosen to prevent the repeated notes\n",
    "# alters probability vector and takes largest probability\n",
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.exp(np.log(preds) / temperature)\n",
    "    preds = preds / np.sum(preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "zjWjzlEXui7-"
   },
   "outputs": [],
   "source": [
    "# use predicted note and append to end of input sequence, then cut off first note of the input sequence and keep shifting\n",
    "def music_maker(seed_vec, model_type, number_unique, unique, diversity, num_notes=64):\n",
    "    music = []\n",
    "    arr = np.zeros((len(seed_vec) + num_notes, number_unique))\n",
    "    for c, i in enumerate(seed_vec):\n",
    "        arr[c] = i\n",
    "\n",
    "    for i in range(0, num_notes, 1):\n",
    "        d_arr = np.zeros(number_unique)\n",
    "        pred = model_type.predict(\n",
    "            np.reshape(\n",
    "                arr[i : len(arr) - num_notes + i],\n",
    "                (1, len(arr[i : len(arr) - num_notes + i]), number_unique),\n",
    "            ),\n",
    "            verbose=0,\n",
    "        )[0]\n",
    "        diverse = sample(pred, diversity) # calling sample function when you have a prediction\n",
    "        d_arr[diverse] = 1\n",
    "        music.append(one_hot_decode(d_arr, all_values=unique)[0])\n",
    "\n",
    "        arr[len(seed_vec) + i] = d_arr\n",
    "\n",
    "    return music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EfvuENYGWFkf"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m randnum \u001b[39m=\u001b[39m random\u001b[39m.\u001b[39mrandrange(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(X_test_note))\n\u001b[1;32m      2\u001b[0m test_note \u001b[39m=\u001b[39m X_test_note[randnum]\n\u001b[1;32m      3\u001b[0m test_offset \u001b[39m=\u001b[39m X_test_off[randnum]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random' is not defined"
     ]
    }
   ],
   "source": [
    "randnum = random.randrange(0, len(X_test_note)) # chose the same random segment from the notes, offset, and duration, \n",
    "test_note = X_test_note[randnum]\n",
    "test_offset = X_test_off[randnum]\n",
    "test_dur = X_test_dur[randnum]\n",
    "generated_music_note = music_maker(\n",
    "    test_note, model_notes, unique_note_number, unique_notes, 0.7 # higher diversity for notes and offsets beecause we wanted more variability?\n",
    ")\n",
    "generated_music_offset = music_maker(\n",
    "    test_offset, model_offsets, unique_offset_number, unique_offsets, 0.7\n",
    ")\n",
    "generated_music_duration = music_maker(\n",
    "    test_dur, model_durations, unique_duration_number, unique_durations, 0.2 # less diversity because model was more confident based on probability vector\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "Xv54x8ozxBBH"
   },
   "outputs": [],
   "source": [
    "# turn one of encoded back to original note form\n",
    "seed_notes = []\n",
    "seed_offsets = []\n",
    "seed_durations = []\n",
    "for n in test_note:\n",
    "    seed_notes.append(one_hot_decode(n, unique_notes)[0])\n",
    "for o in test_offset:\n",
    "    seed_offsets.append(one_hot_decode(o, unique_offsets)[0])\n",
    "for d in test_dur:\n",
    "    seed_durations.append(one_hot_decode(d, unique_durations)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "Sido9o5NjHK9"
   },
   "outputs": [],
   "source": [
    "def to_midi(notes, offsets, durations):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "    Takes midi metadata and converts it to a Music21 stream. The stream can then easily be converted into a midi file.\n",
    "\n",
    "    Parameters:\n",
    "    metadata: midi metadata (notes,chords,offsets)\n",
    "\n",
    "    Returns:\n",
    "    list: Music21 stream object\n",
    "    \"\"\"\n",
    "    offset = offsets[0]\n",
    "    s = stream.Stream()\n",
    "    for i, ele in enumerate(notes):\n",
    "        if ele[0].isalpha():\n",
    "            n = note.Note(ele)\n",
    "            try:\n",
    "                n.quarterLength = float(durations[i])\n",
    "            except:\n",
    "                n.quarterLength = Fraction(durations[i])\n",
    "\n",
    "            s.insert(offset, n)\n",
    "\n",
    "            offset += offsets[i]\n",
    "        else:\n",
    "            chords = list(map(int, ele.split(\".\")))\n",
    "            c = chord.Chord(chords)\n",
    "\n",
    "            try:\n",
    "                c.quarterLength = float(durations[i])\n",
    "            except:\n",
    "                c.quarterLength = Fraction(durations[i])\n",
    "\n",
    "            s.insert(offset, c)\n",
    "\n",
    "            offset += offsets[i]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "qqCfHbIPxpPr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'seed_classical.mid'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_stream = to_midi(generated_music_note, generated_music_offset, generated_music_duration)\n",
    "generated_stream.write(\"midi\", \"generated_classical.mid\")\n",
    "to_midi(seed_notes, seed_offsets, seed_durations).write(\"midi\", \"seed_classical.mid\")\n",
    "\n",
    "# biggest improvement is being able to split up process into different files so we can manage ram better\n",
    "# right now we make massive array of notes so at some point the notes between song segments will overlap ie 16 notes from 1 song and 48 from another, we could\n",
    "# have found different random sequences from different songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sheetmusic(stream):\n",
    "    \"\"\"\n",
    "    Summary:\n",
    "    Takes Stream object and converts it to sheet music.\n",
    "\n",
    "    Parameters:\n",
    "    midi file\n",
    "\n",
    "    Returns:\n",
    "    list: Music21 stream object\n",
    "    \"\"\"\n",
    "    stream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SubConverterException",
     "evalue": "Cannot find a path to the 'mscore' file at /Applications/MuseScore 3.app/Contents/MacOS/mscore -- download MuseScore",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSubConverterException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m d5 \u001b[39m=\u001b[39m note\u001b[39m.\u001b[39mNote(\u001b[39m\"\u001b[39m\u001b[39mD5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m s1\u001b[39m.\u001b[39mappend(d5)\n\u001b[0;32m----> 4\u001b[0m s1\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/stream/base.py:397\u001b[0m, in \u001b[0;36mStream.show\u001b[0;34m(self, fmt, app, **keywords)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39misSorted \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mautoSort:\n\u001b[1;32m    396\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msort()\n\u001b[0;32m--> 397\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mshow(fmt\u001b[39m=\u001b[39;49mfmt, app\u001b[39m=\u001b[39;49mapp, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/base.py:2888\u001b[0m, in \u001b[0;36mMusic21Object.show\u001b[0;34m(self, fmt, app, **keywords)\u001b[0m\n\u001b[1;32m   2886\u001b[0m scClass \u001b[39m=\u001b[39m common\u001b[39m.\u001b[39mfindSubConverterForFormat(regularizedConverterFormat)\n\u001b[1;32m   2887\u001b[0m formatWriter \u001b[39m=\u001b[39m scClass()\n\u001b[0;32m-> 2888\u001b[0m \u001b[39mreturn\u001b[39;00m formatWriter\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2889\u001b[0m                          regularizedConverterFormat,\n\u001b[1;32m   2890\u001b[0m                          app\u001b[39m=\u001b[39;49mapp,\n\u001b[1;32m   2891\u001b[0m                          subformats\u001b[39m=\u001b[39;49msubformats,\n\u001b[1;32m   2892\u001b[0m                          \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/subConverters.py:395\u001b[0m, in \u001b[0;36mConverterIPython.show\u001b[0;34m(self, obj, fmt, app, subformats, **keywords)\u001b[0m\n\u001b[1;32m    392\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(obj\u001b[39m.\u001b[39mscores)\n\u001b[1;32m    394\u001b[0m \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m scores:\n\u001b[0;32m--> 395\u001b[0m     fp \u001b[39m=\u001b[39m helperSubConverter\u001b[39m.\u001b[39;49mwrite(s,\n\u001b[1;32m    396\u001b[0m                                   helperFormat,\n\u001b[1;32m    397\u001b[0m                                   subformats\u001b[39m=\u001b[39;49mhelperSubformats,\n\u001b[1;32m    398\u001b[0m                                   \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords\n\u001b[1;32m    399\u001b[0m                                   )\n\u001b[1;32m    401\u001b[0m     \u001b[39mif\u001b[39;00m helperSubformats[\u001b[39m0\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    402\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m(environLocal[\u001b[39m'\u001b[39m\u001b[39mmusescoreDirectPNGPath\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m/skip\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/subConverters.py:1138\u001b[0m, in \u001b[0;36mConverterMusicXML.write\u001b[0;34m(self, obj, fmt, fp, subformats, makeNotation, compress, **keywords)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     defaults\u001b[39m.\u001b[39mauthor \u001b[39m=\u001b[39m savedDefaultAuthor\n\u001b[1;32m   1135\u001b[0m \u001b[39mif\u001b[39;00m (subformats \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[39mand\u001b[39;00m (\u001b[39m'\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m subformats \u001b[39mor\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpdf\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m subformats)\n\u001b[1;32m   1137\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mstr\u001b[39m(environLocal[\u001b[39m'\u001b[39m\u001b[39mmusescoreDirectPNGPath\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39m/skip\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m-> 1138\u001b[0m     outFp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrunThroughMusescore(xmlFp, subformats, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkeywords)\n\u001b[1;32m   1139\u001b[0m \u001b[39melif\u001b[39;00m compress:\n\u001b[1;32m   1140\u001b[0m     archiveTools\u001b[39m.\u001b[39mcompressXML(xmlFp,\n\u001b[1;32m   1141\u001b[0m                              deleteOriginal\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                              silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m   1143\u001b[0m                              strictMxlCheck\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniforge3/envs/env_tf/lib/python3.9/site-packages/music21/converter/subConverters.py:972\u001b[0m, in \u001b[0;36mConverterMusicXML.runThroughMusescore\u001b[0;34m(self, fp, subformats, dpi, **keywords)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[39mraise\u001b[39;00m SubConverterException(\n\u001b[1;32m    969\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mTo create PNG files directly from MusicXML you need to download MuseScore and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    970\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mput a link to it in your .music21rc via Environment.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    971\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m musescorePath\u001b[39m.\u001b[39mexists():\n\u001b[0;32m--> 972\u001b[0m     \u001b[39mraise\u001b[39;00m SubConverterException(\n\u001b[1;32m    973\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find a path to the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mmscore\u001b[39m\u001b[39m'\u001b[39m\u001b[39m file at \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    974\u001b[0m         \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmusescorePath\u001b[39m}\u001b[39;00m\u001b[39m -- download MuseScore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m subformats \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m     subformatExtension \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mSubConverterException\u001b[0m: Cannot find a path to the 'mscore' file at /Applications/MuseScore 3.app/Contents/MacOS/mscore -- download MuseScore"
     ]
    }
   ],
   "source": [
    "s1 = stream.Stream()\n",
    "d5 = note.Note(\"D5\")\n",
    "s1.append(d5)\n",
    "s1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env_tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 | packaged by conda-forge | (main, May 27 2022, 17:01:00) \n[Clang 13.0.1 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "844472d4514335056b0586d8ae88a5f935d47f39a1fefde0e595e1c9f1065a85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
