{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarlonGrandy/LSTMMusicGeneration/blob/main/LSTMMusicGenerationPipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiAHuMXqtg9k",
        "outputId": "852d71df-402f-4726-8fe6-92872eff82e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aPMvatbQ7_C4"
      },
      "outputs": [],
      "source": [
        "#import statements\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from music21 import converter, instrument, note, chord, stream, duration\n",
        "import glob\n",
        "import os\n",
        "from itertools import chain\n",
        "import copy\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from keras.layers import CuDNNLSTM,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import argmax\n",
        "from fractions import Fraction\n",
        "import gc\n",
        "import random\n",
        "import keras.utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2RBI4UDFDr6A"
      },
      "outputs": [],
      "source": [
        "def data_extractor(directory):\n",
        "  \"\"\"\n",
        "    Summary:\n",
        "    Function converts midi files to metadata and appends nested metadata lists into one large list\n",
        "    composed of all the songs in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    directory: String representation of directory where midi files are located\n",
        "\n",
        "    Returns:\n",
        "    list: sequential midi file metadata \n",
        "   \"\"\"\n",
        "  notes = []\n",
        "  offsets = []\n",
        "  durations = []\n",
        "  for file in glob.glob(directory):\n",
        "          mid = converter.parse(file)\n",
        "          notes_to_parse = None\n",
        "          prev_offset = 0\n",
        "          \n",
        "          try: \n",
        "              s2 = instrument.partitionByInstrument(mid)\n",
        "              notes_to_parse = s2.parts[0].recurse() \n",
        "              \n",
        "          except: \n",
        "              notes_to_parse = mid.flat.notes\n",
        "\n",
        "          for i,element in enumerate(notes_to_parse):\n",
        "              if isinstance(element, note.Note):\n",
        "                  notes.append(str(element.pitch))\n",
        "                  \n",
        "                  durations.append(str(element.quarterLength))\n",
        "                  \n",
        "                  offset_dif = float(element.offset-prev_offset)\n",
        "              \n",
        "                  offsets.append(round(offset_dif,3))\n",
        "                  prev_offset = element.offset\n",
        "             \n",
        "                 \n",
        "              elif isinstance(element, chord.Chord):\n",
        "                  notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "                  offset_dif = float(element.offset-prev_offset)\n",
        "\n",
        "                  durations.append(str(element.quarterLength))\n",
        "                  \n",
        "                  offsets.append(round(offset_dif,3))\n",
        "                  prev_offset = element.offset\n",
        "\n",
        "  return [notes,offsets,durations]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uM7ofNWWbp4Q"
      },
      "outputs": [],
      "source": [
        "data = data_extractor(\"/content/drive/MyDrive/midi_stuff/*.mid\")\n",
        "note_data = data[0]\n",
        "offset_data = data[1]\n",
        "duration_data = data[2]\n",
        "\n",
        "unique_note_number = len(list(set(note_data)))\n",
        "unique_notes = sorted(list(set(note_data)))\n",
        "unique_offset_number = len(list(set(offset_data)))\n",
        "unique_offsets = sorted(list(set(offset_data)))\n",
        "unique_duration_number = len(list(set(duration_data)))\n",
        "unique_durations = sorted(list(set(duration_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FcFLfinnvOHJ"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(vector, all_values):\n",
        "  encoded_vectors = []\n",
        "  int_to_index = dict((c, i) for i, c in enumerate(all_values))\n",
        "  for i in vector:\n",
        "    zero = [0]*(len(all_values)-1)\n",
        "    zero.insert(int_to_index[i],1)\n",
        "    encoded_vectors.append(zero)\n",
        "  \n",
        "  return encoded_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xuDs9q4Ftunv"
      },
      "outputs": [],
      "source": [
        "from numpy import argmax\n",
        "def one_hot_decode(vector,all_values):\n",
        "  decoded_vector = []\n",
        "  index_to_int = dict((i, c) for i, c in enumerate(all_values))\n",
        "  decoded_vector.append(index_to_int[argmax(vector)])\n",
        "  return decoded_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vvLcXr-7vr0j"
      },
      "outputs": [],
      "source": [
        "segment_length = 64\n",
        "def make_segments(data_array,unique_values, seq_length = segment_length):\n",
        "  input_seq = []\n",
        "  output_seq = []\n",
        "\n",
        "  processed_data = one_hot_encode(data_array,unique_values)\n",
        "  \n",
        "  for i in range(0,len(processed_data) - seq_length,1):\n",
        "    input_seq.append([processed_data[i:i+seq_length]])\n",
        "    output_seq.append(processed_data[seq_length + i])\n",
        "\n",
        "  del processed_data;gc.collect()\n",
        "  \n",
        "  input_seq = np.reshape(input_seq,(len(input_seq), segment_length,len(unique_values)))\n",
        "  output_seq = np.array(output_seq)\n",
        "\n",
        "  return input_seq, output_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "utzraCh5bx4M"
      },
      "outputs": [],
      "source": [
        "note_model_data = make_segments(data_array = note_data, unique_values = unique_notes)\n",
        "offset_model_data = make_segments(data_array = offset_data, unique_values = unique_offsets)\n",
        "duration_model_data = make_segments(data_array = duration_data, unique_values = unique_durations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XYOpsKKdquwj"
      },
      "outputs": [],
      "source": [
        "X_train_note, X_test_note, y_train_note, y_test_note = train_test_split(note_model_data[0], note_model_data[1],test_size=0.2)\n",
        "X_train_off, X_test_off, y_train_off, y_test_off = train_test_split(offset_model_data[0], offset_model_data[1],test_size=0.2)\n",
        "X_train_dur, X_test_dur, y_train_dur, y_test_dur = train_test_split(duration_model_data[0], duration_model_data[1],test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del note_model_data\n",
        "del offset_model_data\n",
        "del duration_model_data\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fJhKOo-5swc",
        "outputId": "363060c0-31c4-4b0e-b648-25925fce0b24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xlEoPwhuwo1i"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape,output_shape):\n",
        "  model = Sequential()\n",
        "  model.add(CuDNNLSTM(512,input_shape=input_shape,return_sequences=False))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(128))\n",
        "  model.add(Dense(output_shape,activation = 'softmax'))\n",
        "\n",
        "  model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=Adam(learning_rate = .001),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hsMf8cKdb8MF"
      },
      "outputs": [],
      "source": [
        "model_notes = make_model(input_shape = (segment_length,unique_note_number), output_shape = unique_note_number)\n",
        "model_offsets = make_model(input_shape = (segment_length,unique_offset_number), output_shape = unique_offset_number)\n",
        "model_durations = make_model(input_shape = (segment_length,unique_duration_number), output_shape = unique_duration_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0zDE5bAKcNAY"
      },
      "outputs": [],
      "source": [
        "my_callbacks = [tf.keras.callbacks.EarlyStopping(patience=2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQq6PZXycBIB",
        "outputId": "856d560d-7e50-49b7-fc5b-783af2891c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "1387/1387 [==============================] - 28s 16ms/step - loss: 4.1239 - accuracy: 0.0706 - val_loss: 3.7334 - val_accuracy: 0.1064\n",
            "Epoch 2/150\n",
            "1387/1387 [==============================] - 20s 15ms/step - loss: 3.5292 - accuracy: 0.1414 - val_loss: 3.3729 - val_accuracy: 0.1676\n",
            "Epoch 3/150\n",
            "1387/1387 [==============================] - 20s 15ms/step - loss: 3.2804 - accuracy: 0.1906 - val_loss: 3.1766 - val_accuracy: 0.2114\n",
            "Epoch 4/150\n",
            "1387/1387 [==============================] - 20s 14ms/step - loss: 3.0365 - accuracy: 0.2330 - val_loss: 3.0309 - val_accuracy: 0.2416\n",
            "Epoch 5/150\n",
            "1387/1387 [==============================] - 20s 14ms/step - loss: 2.8655 - accuracy: 0.2679 - val_loss: 2.9091 - val_accuracy: 0.2734\n",
            "Epoch 6/150\n",
            "1387/1387 [==============================] - 20s 14ms/step - loss: 2.6746 - accuracy: 0.3084 - val_loss: 2.7950 - val_accuracy: 0.3004\n",
            "Epoch 7/150\n",
            "1387/1387 [==============================] - 20s 14ms/step - loss: 2.4595 - accuracy: 0.3558 - val_loss: 2.6665 - val_accuracy: 0.3384\n",
            "Epoch 8/150\n",
            "1387/1387 [==============================] - 20s 14ms/step - loss: 2.2017 - accuracy: 0.4170 - val_loss: 2.5166 - val_accuracy: 0.3787\n",
            "Epoch 9/150\n",
            "1387/1387 [==============================] - 20s 15ms/step - loss: 1.9330 - accuracy: 0.4826 - val_loss: 2.4294 - val_accuracy: 0.4119\n",
            "Epoch 10/150\n",
            "1387/1387 [==============================] - 20s 15ms/step - loss: 1.6600 - accuracy: 0.5508 - val_loss: 2.2785 - val_accuracy: 0.4738\n",
            "Epoch 11/150\n",
            "1387/1387 [==============================] - 20s 15ms/step - loss: 1.4045 - accuracy: 0.6138 - val_loss: 2.2478 - val_accuracy: 0.4909\n",
            "Epoch 12/150\n",
            "  14/1387 [..............................] - ETA: 17s - loss: 1.1091 - accuracy: 0.6674"
          ]
        }
      ],
      "source": [
        "history_note = model_notes.fit(X_train_note,y_train_note,epochs=150, validation_split = 0.2, callbacks = my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGp9R-18cEbB"
      },
      "outputs": [],
      "source": [
        "history_offset = model_offsets.fit(X_train_off,y_train_off,epochs=150, validation_split = 0.2,callbacks = my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_duration = model_durations.fit(X_train_dur,y_train_dur,epochs=150, validation_split = 0.2,callbacks = my_callbacks)"
      ],
      "metadata": {
        "id": "6RMQVDFH7wsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.exp(np.log(preds) / temperature)  \n",
        "    preds = preds / np.sum(preds)                \n",
        "    probas = np.random.multinomial(1, preds, 1)  \n",
        "    return np.argmax(probas)                     "
      ],
      "metadata": {
        "id": "is75YDQUyDxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjWjzlEXui7-"
      },
      "outputs": [],
      "source": [
        "def music_maker(seed_vec, model_type, number_unique, unique, diversity, num_notes = 64):\n",
        "  music = []\n",
        "  arr = np.zeros((len(seed_vec)+num_notes,number_unique))\n",
        "  for c,i in enumerate(seed_vec):\n",
        "    arr[c] = i\n",
        "\n",
        "  for i in range(0,num_notes,1):\n",
        "    d_arr = np.zeros(number_unique)\n",
        "    pred = model_type.predict(np.reshape(arr[i:len(arr)-num_notes+i], (1, len(arr[i:len(arr)-num_notes+i]),number_unique)),verbose = 0)[0]\n",
        "    diverse = sample(pred, diversity)\n",
        "    d_arr[diverse] = 1\n",
        "    music.append(one_hot_decode(d_arr,all_values = unique)[0])\n",
        "\n",
        "    arr[len(seed_vec)+i] = d_arr\n",
        "  \n",
        "  return music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfvuENYGWFkf"
      },
      "outputs": [],
      "source": [
        "randnum = random.randrange(0,len(X_test_note))\n",
        "test_note = X_test_note[randnum]\n",
        "test_offset = X_test_off[randnum]\n",
        "test_dur = X_test_dur[randnum]\n",
        "generated_music_note = music_maker(test_note, model_notes, unique_note_number, unique_notes, 0.7)\n",
        "generated_music_offset = music_maker(test_offset,model_offsets,unique_offset_number, unique_offsets, 0.7)\n",
        "generated_music_duration = music_maker(test_dur, model_durations, unique_duration_number, unique_durations, 0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_notes = []\n",
        "seed_offsets = []\n",
        "seed_durations = []\n",
        "for n in test_note:\n",
        "  seed_notes.append(one_hot_decode(n ,unique_notes)[0]) \n",
        "for o in test_offset:\n",
        "  seed_offsets.append(one_hot_decode(o ,unique_offsets)[0]) \n",
        "for d in test_dur:\n",
        "  seed_durations.append(one_hot_decode(d, unique_durations)[0])"
      ],
      "metadata": {
        "id": "Xv54x8ozxBBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_midi(notes, offsets, durations):\n",
        "  \"\"\"\n",
        "  Summary:\n",
        "  Takes midi metadata and converts it to a Music21 stream. The stream can then easily be converted into a midi file.\n",
        "\n",
        "  Parameters:\n",
        "  metadata: midi metadata (notes,chords,offsets)\n",
        "\n",
        "  Returns:\n",
        "  list: Music21 stream object\n",
        "  \"\"\"\n",
        "  offset = offsets[0]\n",
        "  s = stream.Stream()\n",
        "  for i,ele in enumerate(notes):\n",
        "    if ele[0].isalpha():\n",
        "      n = note.Note(ele)\n",
        "      try:\n",
        "        n.quarterLength = float(durations[i])\n",
        "      except:\n",
        "        n.quarterLength = Fraction(durations[i])\n",
        "\n",
        "      s.insert(offset,n)\n",
        "\n",
        "      offset += offsets[i]\n",
        "    else:\n",
        "      chords = list(map(int,ele.split('.')))\n",
        "      c = chord.Chord(chords)\n",
        "\n",
        "      try:\n",
        "        c.quarterLength = float(durations[i])\n",
        "      except:\n",
        "        c.quarterLength = Fraction(durations[i])\n",
        "\n",
        "      s.insert(offset,c)\n",
        "\n",
        "      offset += offsets[i]\n",
        "  return s"
      ],
      "metadata": {
        "id": "Sido9o5NjHK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqCfHbIPxpPr"
      },
      "outputs": [],
      "source": [
        "to_midi(generated_music_note,generated_music_offset, generated_music_duration).write('midi', \"generated_classical.mid\")\n",
        "to_midi(seed_notes,seed_offsets,seed_durations).write('midi', \"seed_classical.mid\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}