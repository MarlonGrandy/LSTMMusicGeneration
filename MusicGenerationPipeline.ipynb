{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JiAHuMXqtg9k",
        "outputId": "dd5fad72-d0e0-4902-903c-b7f4ef7de1b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPMvatbQ7_C4"
      },
      "outputs": [],
      "source": [
        "#import statements\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from music21 import converter, instrument, note, chord, stream, duration\n",
        "import glob\n",
        "import os\n",
        "from itertools import chain\n",
        "import copy\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from keras.layers import CuDNNLSTM,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy import argmax\n",
        "import gc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2RBI4UDFDr6A"
      },
      "outputs": [],
      "source": [
        "def data_extractor(directory):\n",
        "  \"\"\"\n",
        "    Summary:\n",
        "    Function converts midi files to metadata and appends nested metadata lists into one large list\n",
        "    composed of all the songs in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    directory: String representation of directroy where midi files are located\n",
        "\n",
        "    Returns:\n",
        "    list: sequential midi file metadata \n",
        "   \"\"\"\n",
        "  notes = []\n",
        "  offsets = []\n",
        "  for file in glob.glob(directory):\n",
        "          mid = converter.parse(file)\n",
        "          notes_to_parse = None\n",
        "          prev_offset = 0\n",
        "          \n",
        "          try: \n",
        "              s2 = instrument.partitionByInstrument(mid)\n",
        "              notes_to_parse = s2.parts[0].recurse() \n",
        "              \n",
        "          except: \n",
        "              notes_to_parse = mid.flat.notes\n",
        "\n",
        "          for i,element in enumerate(notes_to_parse):\n",
        "              if isinstance(element, note.Note):\n",
        "                  notes.append(str(element.pitch))\n",
        "                  offset_dif = float(element.offset-prev_offset)\n",
        "              \n",
        "                  offsets.append(round(offset_dif,3))\n",
        "                  prev_offset = element.offset\n",
        "             \n",
        "                 \n",
        "              elif isinstance(element, chord.Chord):\n",
        "                  notes.append('.'.join(str(n) for n in element.normalOrder))\n",
        "                  offset_dif = float(element.offset-prev_offset)\n",
        "                  \n",
        "                  offsets.append(round(offset_dif,3))\n",
        "                  prev_offset = element.offset\n",
        "\n",
        "  return [notes,offsets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uM7ofNWWbp4Q"
      },
      "outputs": [],
      "source": [
        "data = data_extractor(\"/content/drive/MyDrive/midi_files/*.mid\")\n",
        "note_data = data[0]\n",
        "offset_data = data[1]\n",
        "\n",
        "unique_note_number = len(list(set(note_data)))\n",
        "unique_notes = sorted(list(set(note_data)))\n",
        "unique_offset_number = len(list(set(offset_data)))\n",
        "unique_offsets = sorted(list(set(offset_data)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data_pipeline():\n",
        "  data = data_extractor(\"/content/drive/MyDrive/midi_short/*.mid\")\n",
        "  seg = make_segments(data_array = offset_data, unique_values = unique_offsets,segment_type = 'offset')\n",
        "  \n",
        "  check_list = []\n",
        "  for i in seg[0][1]:\n",
        "    check_list.append(one_hot_decode(i,unique_offsets)[0])\n",
        "\n",
        "  if check_list == offset_data[1:len(seg[0][1])+1]:\n",
        "\n",
        "    print('pipeline working')\n",
        "  else:\n",
        "    print('pipeline not working')\n",
        "test_data_pipeline()"
      ],
      "metadata": {
        "id": "G78xJ_cK4s12",
        "outputId": "0dc42dd2-4f69-4202-da03-8ad97de88cc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pipeline working\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "d9-bc5MNv076"
      },
      "outputs": [],
      "source": [
        "def to_midi(notes,offsets):\n",
        "  \"\"\"\n",
        "  Summary:\n",
        "  Takes midi metadata and converts it to a Music21 stream. The stream can then easily be converted into a midi file.\n",
        "\n",
        "  Parameters:\n",
        "  metadata: midi metadata (notes,chords,offsets)\n",
        "\n",
        "  Returns:\n",
        "  list: Music21 stream object\n",
        "  \"\"\"\n",
        "  offset = offsets[0]\n",
        "  s = stream.Stream()\n",
        "  for i,ele in enumerate(notes):\n",
        "    if ele[0].isalpha():\n",
        "      n = note.Note(ele)\n",
        "      s.insert(offset,n)\n",
        "      offset += offsets[i]\n",
        "    else:\n",
        "      chords = list(map(int,ele.split('.')))\n",
        "      c = chord.Chord(chords)\n",
        "      s.insert(offset,c)\n",
        "      offset += offsets[i]\n",
        "  return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FcFLfinnvOHJ"
      },
      "outputs": [],
      "source": [
        "def one_hot_encode(vector, all_values):\n",
        "  encoded_vectors = []\n",
        "  int_to_index = dict((c, i) for i, c in enumerate(all_values))\n",
        "  for i in vector:\n",
        "    zero = [0]*(len(all_values)-1)\n",
        "    zero.insert(int_to_index[i],1)\n",
        "    encoded_vectors.append(zero)\n",
        "  \n",
        "  return encoded_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xuDs9q4Ftunv"
      },
      "outputs": [],
      "source": [
        "from numpy import argmax\n",
        "def one_hot_decode(vector,all_values):\n",
        "  decoded_vector = []\n",
        "  index_to_int = dict((i, c) for i, c in enumerate(all_values))\n",
        "  decoded_vector.append(index_to_int[argmax(vector)])\n",
        "  return decoded_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vvLcXr-7vr0j"
      },
      "outputs": [],
      "source": [
        "import keras.utils\n",
        "segment_length = 64\n",
        "def make_segments(data_array,unique_values, seq_length = segment_length,segment_type = 'note'):\n",
        "  input_seq = []\n",
        "  output_seq = []\n",
        "\n",
        "  processed_data = one_hot_encode(data_array,unique_values)\n",
        "  \n",
        "  for i in range(0,len(processed_data) - seq_length,1):\n",
        "    input_seq.append([processed_data[i:i+seq_length]])\n",
        "    output_seq.append(processed_data[seq_length + i])\n",
        "\n",
        "  del processed_data;gc.collect()\n",
        "  \n",
        "  input_seq = np.stack(arr[0] for arr in input_seq)\n",
        "  output_seq = np.array(output_seq)\n",
        "\n",
        "  return input_seq, output_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utzraCh5bx4M",
        "outputId": "7b5d29e8-2568-44aa-b232-c743fc78d7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
          ]
        }
      ],
      "source": [
        "note_model_data = make_segments(data_array = note_data, unique_values = unique_notes,segment_type = 'note')\n",
        "offset_model_data = make_segments(data_array = offset_data, unique_values = unique_offsets,segment_type = 'offset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XYOpsKKdquwj"
      },
      "outputs": [],
      "source": [
        "X_train_note, X_test_note, y_train_note, y_test_note = train_test_split(note_model_data[0], note_model_data[1],test_size=0.2)\n",
        "X_train_off, X_test_off, y_train_off, y_test_off = train_test_split(offset_model_data[0], offset_model_data[1],test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del note_model_data\n",
        "del offset_model_data\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fJhKOo-5swc",
        "outputId": "347d3332-5a93-4410-94e8-26129c29f6da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xlEoPwhuwo1i"
      },
      "outputs": [],
      "source": [
        "def make_model(input_shape,output_shape):\n",
        "  model = Sequential()\n",
        "  model.add(CuDNNLSTM(512,input_shape=input_shape,return_sequences=False))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(256))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(output_shape,activation = 'softmax'))\n",
        "\n",
        "  model.compile(\n",
        "      loss='categorical_crossentropy',\n",
        "      optimizer=Adam(learning_rate = .001),\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hsMf8cKdb8MF"
      },
      "outputs": [],
      "source": [
        "model_notes = make_model(input_shape = (segment_length,unique_note_number), output_shape = unique_note_number)\n",
        "model_offsets = make_model(input_shape = (segment_length,unique_offset_number), output_shape = unique_offset_number)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "0zDE5bAKcNAY"
      },
      "outputs": [],
      "source": [
        "my_callbacks = [\n",
        "    tf.keras.callbacks.EarlyStopping(patience=10)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQq6PZXycBIB",
        "outputId": "1624fd4a-1181-4e7b-ac4d-5bdf8b226eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "604/604 [==============================] - 15s 15ms/step - loss: 4.2689 - accuracy: 0.0874 - val_loss: 3.7610 - val_accuracy: 0.1437\n",
            "Epoch 2/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 3.6324 - accuracy: 0.1523 - val_loss: 3.4989 - val_accuracy: 0.1596\n",
            "Epoch 3/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 3.3676 - accuracy: 0.1856 - val_loss: 3.2965 - val_accuracy: 0.1905\n",
            "Epoch 4/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 3.1262 - accuracy: 0.2299 - val_loss: 3.1265 - val_accuracy: 0.2360\n",
            "Epoch 5/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 2.9110 - accuracy: 0.2776 - val_loss: 2.9596 - val_accuracy: 0.2698\n",
            "Epoch 6/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 2.6900 - accuracy: 0.3216 - val_loss: 2.8533 - val_accuracy: 0.3122\n",
            "Epoch 7/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 2.4898 - accuracy: 0.3686 - val_loss: 2.7075 - val_accuracy: 0.3406\n",
            "Epoch 8/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 2.3084 - accuracy: 0.4058 - val_loss: 2.5860 - val_accuracy: 0.3735\n",
            "Epoch 9/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 2.1131 - accuracy: 0.4527 - val_loss: 2.5169 - val_accuracy: 0.3998\n",
            "Epoch 10/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 1.9526 - accuracy: 0.4888 - val_loss: 2.4281 - val_accuracy: 0.4377\n",
            "Epoch 11/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 1.7871 - accuracy: 0.5267 - val_loss: 2.3597 - val_accuracy: 0.4557\n",
            "Epoch 12/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 1.6274 - accuracy: 0.5644 - val_loss: 2.3143 - val_accuracy: 0.4698\n",
            "Epoch 13/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 1.4877 - accuracy: 0.5970 - val_loss: 2.3200 - val_accuracy: 0.4899\n",
            "Epoch 14/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 1.3584 - accuracy: 0.6271 - val_loss: 2.2548 - val_accuracy: 0.5203\n",
            "Epoch 15/150\n",
            "604/604 [==============================] - 9s 14ms/step - loss: 1.2365 - accuracy: 0.6609 - val_loss: 2.2421 - val_accuracy: 0.5286\n",
            "Epoch 16/150\n",
            "604/604 [==============================] - 9s 14ms/step - loss: 1.1308 - accuracy: 0.6825 - val_loss: 2.2848 - val_accuracy: 0.5400\n",
            "Epoch 17/150\n",
            "604/604 [==============================] - 9s 14ms/step - loss: 1.0355 - accuracy: 0.7090 - val_loss: 2.2655 - val_accuracy: 0.5569\n",
            "Epoch 18/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 0.9391 - accuracy: 0.7274 - val_loss: 2.2594 - val_accuracy: 0.5716\n",
            "Epoch 19/150\n",
            "604/604 [==============================] - 9s 14ms/step - loss: 0.8534 - accuracy: 0.7509 - val_loss: 2.2876 - val_accuracy: 0.5772\n",
            "Epoch 20/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 0.7934 - accuracy: 0.7665 - val_loss: 2.3371 - val_accuracy: 0.5928\n",
            "Epoch 21/150\n",
            "604/604 [==============================] - 9s 14ms/step - loss: 0.7210 - accuracy: 0.7895 - val_loss: 2.3584 - val_accuracy: 0.5957\n",
            "Epoch 22/150\n",
            "604/604 [==============================] - 9s 14ms/step - loss: 0.6633 - accuracy: 0.8037 - val_loss: 2.3794 - val_accuracy: 0.5957\n",
            "Epoch 23/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 0.6116 - accuracy: 0.8179 - val_loss: 2.4651 - val_accuracy: 0.5992\n",
            "Epoch 24/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 0.5729 - accuracy: 0.8281 - val_loss: 2.4813 - val_accuracy: 0.6046\n",
            "Epoch 25/150\n",
            "604/604 [==============================] - 8s 14ms/step - loss: 0.5229 - accuracy: 0.8405 - val_loss: 2.5194 - val_accuracy: 0.6068\n"
          ]
        }
      ],
      "source": [
        "history_note = model_notes.fit(X_train_note,y_train_note,epochs=150, validation_split = 0.2, callbacks = my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGp9R-18cEbB",
        "outputId": "afe07d02-af48-4743-da4f-45d5503a604e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "604/604 [==============================] - 8s 12ms/step - loss: 1.1462 - accuracy: 0.5841 - val_loss: 1.0216 - val_accuracy: 0.6124\n",
            "Epoch 2/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.9516 - accuracy: 0.6556 - val_loss: 0.8726 - val_accuracy: 0.6851\n",
            "Epoch 3/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.8451 - accuracy: 0.6986 - val_loss: 0.8188 - val_accuracy: 0.7099\n",
            "Epoch 4/150\n",
            "604/604 [==============================] - 8s 13ms/step - loss: 0.7716 - accuracy: 0.7233 - val_loss: 0.7167 - val_accuracy: 0.7422\n",
            "Epoch 5/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.7263 - accuracy: 0.7408 - val_loss: 0.7043 - val_accuracy: 0.7571\n",
            "Epoch 6/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.6934 - accuracy: 0.7511 - val_loss: 0.6778 - val_accuracy: 0.7605\n",
            "Epoch 7/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.6611 - accuracy: 0.7638 - val_loss: 0.6674 - val_accuracy: 0.7658\n",
            "Epoch 8/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.6289 - accuracy: 0.7790 - val_loss: 0.6333 - val_accuracy: 0.7839\n",
            "Epoch 9/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.5997 - accuracy: 0.7909 - val_loss: 0.6049 - val_accuracy: 0.7965\n",
            "Epoch 10/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.5632 - accuracy: 0.8035 - val_loss: 0.5860 - val_accuracy: 0.8029\n",
            "Epoch 11/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.5319 - accuracy: 0.8168 - val_loss: 0.5827 - val_accuracy: 0.8116\n",
            "Epoch 12/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.4994 - accuracy: 0.8276 - val_loss: 0.5609 - val_accuracy: 0.8139\n",
            "Epoch 13/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.4703 - accuracy: 0.8414 - val_loss: 0.5308 - val_accuracy: 0.8290\n",
            "Epoch 14/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.4410 - accuracy: 0.8526 - val_loss: 0.5338 - val_accuracy: 0.8308\n",
            "Epoch 15/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.4082 - accuracy: 0.8618 - val_loss: 0.5359 - val_accuracy: 0.8333\n",
            "Epoch 16/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.3876 - accuracy: 0.8703 - val_loss: 0.5141 - val_accuracy: 0.8437\n",
            "Epoch 17/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.3614 - accuracy: 0.8772 - val_loss: 0.5116 - val_accuracy: 0.8480\n",
            "Epoch 18/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.3359 - accuracy: 0.8887 - val_loss: 0.5066 - val_accuracy: 0.8522\n",
            "Epoch 19/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.3197 - accuracy: 0.8917 - val_loss: 0.5225 - val_accuracy: 0.8532\n",
            "Epoch 20/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.2991 - accuracy: 0.8977 - val_loss: 0.5162 - val_accuracy: 0.8557\n",
            "Epoch 21/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.2783 - accuracy: 0.9063 - val_loss: 0.5018 - val_accuracy: 0.8611\n",
            "Epoch 22/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.2689 - accuracy: 0.9099 - val_loss: 0.5170 - val_accuracy: 0.8636\n",
            "Epoch 23/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.2518 - accuracy: 0.9174 - val_loss: 0.5065 - val_accuracy: 0.8663\n",
            "Epoch 24/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.2258 - accuracy: 0.9263 - val_loss: 0.5458 - val_accuracy: 0.8706\n",
            "Epoch 25/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.2197 - accuracy: 0.9268 - val_loss: 0.5236 - val_accuracy: 0.8768\n",
            "Epoch 26/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.2022 - accuracy: 0.9339 - val_loss: 0.5431 - val_accuracy: 0.8689\n",
            "Epoch 27/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.1968 - accuracy: 0.9362 - val_loss: 0.5543 - val_accuracy: 0.8725\n",
            "Epoch 28/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.1872 - accuracy: 0.9387 - val_loss: 0.5531 - val_accuracy: 0.8778\n",
            "Epoch 29/150\n",
            "604/604 [==============================] - 7s 11ms/step - loss: 0.1817 - accuracy: 0.9400 - val_loss: 0.5847 - val_accuracy: 0.8725\n",
            "Epoch 30/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.1694 - accuracy: 0.9434 - val_loss: 0.5554 - val_accuracy: 0.8714\n",
            "Epoch 31/150\n",
            "604/604 [==============================] - 7s 12ms/step - loss: 0.1575 - accuracy: 0.9469 - val_loss: 0.5983 - val_accuracy: 0.8760\n"
          ]
        }
      ],
      "source": [
        "history_offset = model_offsets.fit(X_train_off,y_train_off,epochs=150, validation_split = 0.2,callbacks = my_callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"Helper function to sample an index from a probability array.\"\"\"\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.exp(np.log(preds) / temperature)  \n",
        "    preds = preds / np.sum(preds)                \n",
        "    probas = np.random.multinomial(1, preds, 1)  \n",
        "    return np.argmax(probas)                     "
      ],
      "metadata": {
        "id": "is75YDQUyDxj"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "zjWjzlEXui7-"
      },
      "outputs": [],
      "source": [
        "def music_maker(seed_vec,model_type,number_unique,unique,num_notes = 64):\n",
        "  music = []\n",
        "  diversity = 0.7\n",
        "  arr = np.zeros((len(seed_vec)+num_notes,number_unique))\n",
        "  for c,i in enumerate(seed_vec):\n",
        "    arr[c] = i\n",
        "\n",
        "  for i in range(0,num_notes,1):\n",
        "    d_arr = np.zeros(number_unique)\n",
        "    pred = model_type.predict(np.reshape(arr[i:len(arr)-num_notes+i], (1, len(arr[i:len(arr)-num_notes+i]),number_unique)),verbose = 0)[0]\n",
        "    diverse = sample(pred, diversity)\n",
        "    d_arr[diverse] = 1\n",
        "    music.append(one_hot_decode(d_arr,all_values = unique)[0])\n",
        "\n",
        "    arr[len(seed_vec)+i] = d_arr\n",
        "  \n",
        "  return music"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "EfvuENYGWFkf"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "randnum = random.randrange(0,len(X_test_note))\n",
        "test_note = X_test_note[randnum]\n",
        "test_offset = X_test_off[randnum]\n",
        "generated_music_note = music_maker(test_note, model_notes, unique_note_number,unique_notes)\n",
        "generated_music_offset = music_maker(test_offset,model_offsets,unique_offset_number,unique_offsets)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_notes = []\n",
        "seed_offsets = []\n",
        "for n in test_note:\n",
        "  seed_notes.append(one_hot_decode(n ,unique_notes)[0]) \n",
        "for o in test_offset:\n",
        "  seed_offsets.append(one_hot_decode(o ,unique_offsets)[0]) "
      ],
      "metadata": {
        "id": "Xv54x8ozxBBH"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qqCfHbIPxpPr",
        "outputId": "d8e7a239-76ab-43c1-c2a4-a45fe9e870ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'seed_classical.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 102
        }
      ],
      "source": [
        "to_midi(generated_music_note,generated_music_offset).write('midi', \"generated_classical.mid\")\n",
        "to_midi(seed_notes,seed_offsets).write('midi', \"seed_classical.mid\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ab-fBMtwswzI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}