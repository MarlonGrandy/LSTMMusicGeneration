{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "JiAHuMXqtg9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4296622-47d3-4412-cfad-12ab02508010"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "aPMvatbQ7_C4"
      },
      "outputs": [],
      "source": [
        "#import statements\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from music21 import converter, instrument, note, chord, stream, duration\n",
        "import glob\n",
        "import os\n",
        "from itertools import chain\n",
        "import copy\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from keras.layers import CuDNNLSTM,Bidirectional\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2RBI4UDFDr6A"
      },
      "outputs": [],
      "source": [
        "\n",
        "def data_extractor(directory):\n",
        "  \"\"\"\n",
        "    Summary:\n",
        "    Function converts midi files to metadata and appends nested metadata lists into one large list\n",
        "    composed of all the songs in the dataset.\n",
        "\n",
        "    Parameters:\n",
        "    directory: String representation of directroy where midi files are located\n",
        "\n",
        "    Returns:\n",
        "    list: sequential midi file metadata \n",
        "   \"\"\"\n",
        "  data = []\n",
        "  for file in glob.glob(directory):\n",
        "          mid = converter.parse(file)\n",
        "          notes_to_parse = None\n",
        "          \n",
        "          try: \n",
        "              s2 = instrument.partitionByInstrument(mid)\n",
        "              notes_to_parse = s2.parts[0].recurse() \n",
        "                 \n",
        "          except: \n",
        "              notes_to_parse = mid.flat.notes\n",
        "\n",
        "          for element in notes_to_parse:\n",
        "              if isinstance(element, note.Note):\n",
        "                  data.append(str(element.pitch))\n",
        "              elif isinstance(element, chord.Chord):\n",
        "                  data.append('.'.join(str(n) for n in element.normalOrder))\n",
        "  return data\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data_extractor(\"/content/drive/MyDrive/midi_files/*.mid\")\n",
        "unique = len(list(set(data)))"
      ],
      "metadata": {
        "id": "IVWK1-yBDB8G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "L_bADzFOjanH",
        "outputId": "504ad777-77f0-49cc-a437-734d2522a6c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([70344., 41703., 29599., 11078., 11534.,  3195.,   933.,   616.,\n",
              "          384.,   109.]),\n",
              " array([  0. ,  37.5,  75. , 112.5, 150. , 187.5, 225. , 262.5, 300. ,\n",
              "        337.5, 375. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "image/png": {
              "width": 393,
              "height": 248
            },
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dict(data, to_int = True):\n",
        "  \"\"\"\n",
        "    Summary:\n",
        "    Function maps either midi metadata into integers and integers back into midi metadata.\n",
        "\n",
        "    Parameters:\n",
        "    data: the data to be used as keys in a dictionary\n",
        "    to_int: if the function maps from midi to int or int to midi\n",
        "    \n",
        "    Returns:\n",
        "    dictionary: dictioanry with keys from data argument \n",
        "   \"\"\"\n",
        "\n",
        "  unnested_data = data\n",
        "  data_set = sorted(set(unnested_data))\n",
        "  if to_int:\n",
        "    notes_to_ints = dict((note,number/unique) for number, note in enumerate(data_set))\n",
        "  else:\n",
        "    notes_to_ints = dict((number,note) for number, note in enumerate(data_set))\n",
        "\n",
        "  return notes_to_ints\n",
        "unique_vals = list(set(list(make_dict(data).values())))"
      ],
      "metadata": {
        "id": "Xi94z4feI-HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def str_to_int():\n",
        "  \"\"\"\n",
        "  Summary:\n",
        "  Function maps original midi list data into the correspondong integer value from the defined ictionary\n",
        "\n",
        "  Returns:\n",
        "  list: integers corresponding to midi metadata \n",
        "  \"\"\"\n",
        "  mapper = make_dict(data)\n",
        "  mapped_sequence = copy.deepcopy(data)\n",
        "  for i in range(len(mapped_sequence)):\n",
        "      mapped_sequence[i] = mapper[mapped_sequence[i]]\n",
        "      \n",
        "  return mapped_sequence"
      ],
      "metadata": {
        "id": "vsIJ_2PMMJFG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def int_to_string(output):\n",
        "  \"\"\"\n",
        "  Summary:\n",
        "  Function maps original integers values back into the midi metadata\n",
        "\n",
        "  Parameters:\n",
        "  output: model output list that need converting back into midi metadata\n",
        "\n",
        "  Returns:\n",
        "  list: midi metadata\n",
        "  \"\"\"\n",
        "  output = [int(val*unique) for val in output]\n",
        "  mapper = make_dict(data,to_int = False)\n",
        "  mapped_sequence = output\n",
        "  for i in range(len(mapped_sequence)):\n",
        "      mapped_sequence[i] = mapper[mapped_sequence[i]]\n",
        "      \n",
        "  return mapped_sequence"
      ],
      "metadata": {
        "id": "ZC-tGdtHNWwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_midi(metadata):\n",
        "  \"\"\"\n",
        "  Summary:\n",
        "  Takes midi metadata and converts it to a Music21 stream. The stream can then easily be converted into a midi file.\n",
        "\n",
        "  Parameters:\n",
        "  metadata: midi metadata (notes,chords,offsets,durations)\n",
        "\n",
        "  Returns:\n",
        "  list: Music21 stream object\n",
        "  \"\"\"\n",
        "  offsets = 0\n",
        "  s = stream.Stream()\n",
        "  for notes in metadata:\n",
        "    if notes[0].isalpha():\n",
        "      n = note.Note(notes)\n",
        "      s.insert(offsets,n)\n",
        "      offsets += 0.25\n",
        "    else:\n",
        "      chords = list(map(int,notes.split('.')))\n",
        "      c = chord.Chord(chords)\n",
        "      s.insert(offsets,c)\n",
        "      offsets += 0.25\n",
        "  return s\n",
        "#to_midi(int_to_string(str_to_int())).write(\"midi\", \"s.mid\")\n"
      ],
      "metadata": {
        "id": "d9-bc5MNv076"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "def one_hot_encode(vector, all_values = unique_vals):\n",
        "  encoded_vectors = []\n",
        "  int_to_index = dict((c, i) for i, c in enumerate(all_values))\n",
        "  \n",
        "  for i in vector:\n",
        "    zero = [0]*(len(all_values)-1)\n",
        "    zero.insert(int_to_index[i],1)\n",
        "    encoded_vectors.append(zero)\n",
        "  \n",
        "  return encoded_vectors"
      ],
      "metadata": {
        "id": "FcFLfinnvOHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "def one_hot_decode(vector, all_values = unique_vals):\n",
        "  decoded_vector = []\n",
        "  all_values = unique_vals\n",
        "  index_to_int = dict((i, c) for i, c in enumerate(all_values))\n",
        "  for vec in vector:\n",
        "    decoded_vector.append(index_to_int[argmax(vec)])\n",
        "  return decoded_vector"
      ],
      "metadata": {
        "id": "xuDs9q4Ftunv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data_pipeline():\n",
        "  data = data_extractor(\"/content/drive/MyDrive/midi_short/*.mid\")\n",
        "  unique_vals = list(set(list(make_dict(data).values())))\n",
        "  unique = len(list(set(data)))\n",
        "  seg = make_segments()\n",
        "  note_list = seg[0][1].tolist()\n",
        "  \n",
        "  if int_to_string(note_list) == data[1:len(seg[0][1])+1]:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "metadata": {
        "id": "0ikTkbEgZdOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.utils\n",
        "\n",
        "def make_segments(seq_length = 25):\n",
        "  if test_data_pipeline:\n",
        "    normal_data = str_to_int()\n",
        "    input_seq = []\n",
        "    output_seq = []\n",
        "    for i in range(0,len(normal_data) - seq_length,1):\n",
        "      input_seq.append([normal_data[i:i+seq_length]])\n",
        "      output_seq.append(normal_data[seq_length + i])\n",
        "    \n",
        "    input_seq = np.stack(arr[0] for arr in input_seq)\n",
        "    output_seq = np.array(one_hot_encode(output_seq))\n",
        "    else:\n",
        "      print(\"Pipeline Broken\")\n",
        "    return input_seq, output_seq\n",
        "model_data = make_segments()"
      ],
      "metadata": {
        "id": "vvLcXr-7vr0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(model_data[0], model_data[1],test_size=0.2)"
      ],
      "metadata": {
        "id": "XYOpsKKdquwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(CuDNNLSTM(512,input_shape=(25, 1),return_sequences=False))\n",
        "model.add(Dense(256))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(unique, activation = 'softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "xlEoPwhuwo1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,y_train,epochs=1000,validation_split = 0.2)"
      ],
      "metadata": {
        "id": "NBGAoY6DwvSA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "89c618fd-8573-4a29-ebbb-ac178306dbf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 4.6351 - accuracy: 0.0253 - val_loss: 4.5807 - val_accuracy: 0.0294\n",
            "Epoch 2/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.5618 - accuracy: 0.0277 - val_loss: 4.5453 - val_accuracy: 0.0287\n",
            "Epoch 3/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.5191 - accuracy: 0.0314 - val_loss: 4.5132 - val_accuracy: 0.0330\n",
            "Epoch 4/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.4926 - accuracy: 0.0340 - val_loss: 4.4860 - val_accuracy: 0.0340\n",
            "Epoch 5/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.4735 - accuracy: 0.0358 - val_loss: 4.4705 - val_accuracy: 0.0356\n",
            "Epoch 6/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.4538 - accuracy: 0.0372 - val_loss: 4.4562 - val_accuracy: 0.0370\n",
            "Epoch 7/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.4340 - accuracy: 0.0398 - val_loss: 4.4395 - val_accuracy: 0.0405\n",
            "Epoch 8/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.4095 - accuracy: 0.0421 - val_loss: 4.4207 - val_accuracy: 0.0446\n",
            "Epoch 9/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.3791 - accuracy: 0.0463 - val_loss: 4.4003 - val_accuracy: 0.0478\n",
            "Epoch 10/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.3426 - accuracy: 0.0520 - val_loss: 4.3619 - val_accuracy: 0.0513\n",
            "Epoch 11/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.3051 - accuracy: 0.0572 - val_loss: 4.3369 - val_accuracy: 0.0581\n",
            "Epoch 12/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.2626 - accuracy: 0.0632 - val_loss: 4.2964 - val_accuracy: 0.0648\n",
            "Epoch 13/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.2112 - accuracy: 0.0715 - val_loss: 4.2620 - val_accuracy: 0.0718\n",
            "Epoch 14/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.1480 - accuracy: 0.0812 - val_loss: 4.2144 - val_accuracy: 0.0829\n",
            "Epoch 15/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 4.0776 - accuracy: 0.0938 - val_loss: 4.1731 - val_accuracy: 0.0881\n",
            "Epoch 16/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 3.9979 - accuracy: 0.1061 - val_loss: 4.1217 - val_accuracy: 0.0998\n",
            "Epoch 17/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 3.9139 - accuracy: 0.1197 - val_loss: 4.0820 - val_accuracy: 0.1096\n",
            "Epoch 18/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 3.8278 - accuracy: 0.1339 - val_loss: 4.0273 - val_accuracy: 0.1204\n",
            "Epoch 19/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 3.7394 - accuracy: 0.1502 - val_loss: 3.9832 - val_accuracy: 0.1303\n",
            "Epoch 20/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 3.6396 - accuracy: 0.1656 - val_loss: 3.9346 - val_accuracy: 0.1403\n",
            "Epoch 21/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 3.5497 - accuracy: 0.1822 - val_loss: 3.9290 - val_accuracy: 0.1486\n",
            "Epoch 22/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 3.4554 - accuracy: 0.1977 - val_loss: 3.8750 - val_accuracy: 0.1594\n",
            "Epoch 23/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 3.3644 - accuracy: 0.2117 - val_loss: 3.8327 - val_accuracy: 0.1675\n",
            "Epoch 24/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 3.2749 - accuracy: 0.2301 - val_loss: 3.8530 - val_accuracy: 0.1792\n",
            "Epoch 25/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 3.1804 - accuracy: 0.2460 - val_loss: 3.8250 - val_accuracy: 0.1870\n",
            "Epoch 26/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 3.1001 - accuracy: 0.2607 - val_loss: 3.8102 - val_accuracy: 0.1931\n",
            "Epoch 27/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 3.0178 - accuracy: 0.2770 - val_loss: 3.8208 - val_accuracy: 0.1962\n",
            "Epoch 28/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 2.9359 - accuracy: 0.2920 - val_loss: 3.8334 - val_accuracy: 0.2039\n",
            "Epoch 29/1000\n",
            "3390/3390 [==============================] - 21s 6ms/step - loss: 2.8579 - accuracy: 0.3075 - val_loss: 3.8401 - val_accuracy: 0.2138\n",
            "Epoch 30/1000\n",
            "3390/3390 [==============================] - 21s 6ms/step - loss: 2.7867 - accuracy: 0.3213 - val_loss: 3.8646 - val_accuracy: 0.2170\n",
            "Epoch 31/1000\n",
            "3390/3390 [==============================] - 21s 6ms/step - loss: 2.7123 - accuracy: 0.3348 - val_loss: 3.8604 - val_accuracy: 0.2247\n",
            "Epoch 32/1000\n",
            "3390/3390 [==============================] - 22s 6ms/step - loss: 2.6396 - accuracy: 0.3504 - val_loss: 3.9207 - val_accuracy: 0.2292\n",
            "Epoch 33/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 2.5801 - accuracy: 0.3626 - val_loss: 3.8874 - val_accuracy: 0.2362\n",
            "Epoch 34/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 2.5087 - accuracy: 0.3752 - val_loss: 4.0048 - val_accuracy: 0.2385\n",
            "Epoch 35/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 2.4438 - accuracy: 0.3897 - val_loss: 3.9380 - val_accuracy: 0.2425\n",
            "Epoch 36/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 2.3783 - accuracy: 0.4030 - val_loss: 4.0069 - val_accuracy: 0.2447\n",
            "Epoch 37/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 2.3301 - accuracy: 0.4143 - val_loss: 4.0098 - val_accuracy: 0.2535\n",
            "Epoch 38/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 2.2662 - accuracy: 0.4271 - val_loss: 3.9976 - val_accuracy: 0.2534\n",
            "Epoch 39/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 2.2156 - accuracy: 0.4379 - val_loss: 4.1422 - val_accuracy: 0.2593\n",
            "Epoch 40/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 2.1628 - accuracy: 0.4481 - val_loss: 4.1382 - val_accuracy: 0.2617\n",
            "Epoch 41/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 2.1125 - accuracy: 0.4596 - val_loss: 4.1447 - val_accuracy: 0.2629\n",
            "Epoch 42/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 2.0616 - accuracy: 0.4719 - val_loss: 4.2120 - val_accuracy: 0.2680\n",
            "Epoch 43/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 2.0129 - accuracy: 0.4806 - val_loss: 4.2105 - val_accuracy: 0.2738\n",
            "Epoch 44/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.9715 - accuracy: 0.4905 - val_loss: 4.2223 - val_accuracy: 0.2744\n",
            "Epoch 45/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.9198 - accuracy: 0.5025 - val_loss: 4.3510 - val_accuracy: 0.2777\n",
            "Epoch 46/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.8834 - accuracy: 0.5103 - val_loss: 4.1987 - val_accuracy: 0.2835\n",
            "Epoch 47/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.8369 - accuracy: 0.5214 - val_loss: 4.3587 - val_accuracy: 0.2835\n",
            "Epoch 48/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.7939 - accuracy: 0.5313 - val_loss: 4.4545 - val_accuracy: 0.2808\n",
            "Epoch 49/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.7591 - accuracy: 0.5386 - val_loss: 4.5025 - val_accuracy: 0.2891\n",
            "Epoch 50/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.7256 - accuracy: 0.5455 - val_loss: 4.5014 - val_accuracy: 0.2885\n",
            "Epoch 51/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.6863 - accuracy: 0.5550 - val_loss: 4.5319 - val_accuracy: 0.2948\n",
            "Epoch 52/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.6474 - accuracy: 0.5645 - val_loss: 4.5584 - val_accuracy: 0.2958\n",
            "Epoch 53/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.6103 - accuracy: 0.5727 - val_loss: 4.7890 - val_accuracy: 0.2937\n",
            "Epoch 54/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.5782 - accuracy: 0.5783 - val_loss: 4.8101 - val_accuracy: 0.2896\n",
            "Epoch 55/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.5464 - accuracy: 0.5867 - val_loss: 4.6693 - val_accuracy: 0.2981\n",
            "Epoch 56/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.5056 - accuracy: 0.5951 - val_loss: 4.7211 - val_accuracy: 0.3018\n",
            "Epoch 57/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.4834 - accuracy: 0.6017 - val_loss: 4.7825 - val_accuracy: 0.3062\n",
            "Epoch 58/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.4516 - accuracy: 0.6081 - val_loss: 4.6779 - val_accuracy: 0.3038\n",
            "Epoch 59/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.4323 - accuracy: 0.6133 - val_loss: 4.8258 - val_accuracy: 0.3066\n",
            "Epoch 60/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.3887 - accuracy: 0.6238 - val_loss: 4.8549 - val_accuracy: 0.3074\n",
            "Epoch 61/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.3653 - accuracy: 0.6290 - val_loss: 4.9783 - val_accuracy: 0.3105\n",
            "Epoch 62/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.3396 - accuracy: 0.6348 - val_loss: 5.1594 - val_accuracy: 0.3090\n",
            "Epoch 63/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.3132 - accuracy: 0.6424 - val_loss: 5.0767 - val_accuracy: 0.3128\n",
            "Epoch 64/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.2891 - accuracy: 0.6472 - val_loss: 5.1291 - val_accuracy: 0.3156\n",
            "Epoch 65/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.2620 - accuracy: 0.6539 - val_loss: 5.1709 - val_accuracy: 0.3141\n",
            "Epoch 66/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.2316 - accuracy: 0.6615 - val_loss: 5.0625 - val_accuracy: 0.3173\n",
            "Epoch 67/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.2081 - accuracy: 0.6674 - val_loss: 5.1828 - val_accuracy: 0.3138\n",
            "Epoch 68/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.1912 - accuracy: 0.6696 - val_loss: 5.3410 - val_accuracy: 0.3191\n",
            "Epoch 69/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.1614 - accuracy: 0.6793 - val_loss: 5.2905 - val_accuracy: 0.3197\n",
            "Epoch 70/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.1405 - accuracy: 0.6837 - val_loss: 5.3837 - val_accuracy: 0.3188\n",
            "Epoch 71/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.1206 - accuracy: 0.6885 - val_loss: 5.4802 - val_accuracy: 0.3199\n",
            "Epoch 72/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.1021 - accuracy: 0.6922 - val_loss: 5.4096 - val_accuracy: 0.3216\n",
            "Epoch 73/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.0750 - accuracy: 0.6989 - val_loss: 5.4675 - val_accuracy: 0.3257\n",
            "Epoch 74/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.0569 - accuracy: 0.7024 - val_loss: 5.5288 - val_accuracy: 0.3243\n",
            "Epoch 75/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.0381 - accuracy: 0.7091 - val_loss: 5.5158 - val_accuracy: 0.3257\n",
            "Epoch 76/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.0199 - accuracy: 0.7123 - val_loss: 5.5938 - val_accuracy: 0.3275\n",
            "Epoch 77/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 1.0025 - accuracy: 0.7179 - val_loss: 5.6108 - val_accuracy: 0.3295\n",
            "Epoch 78/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.9790 - accuracy: 0.7230 - val_loss: 5.7417 - val_accuracy: 0.3267\n",
            "Epoch 79/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.9676 - accuracy: 0.7273 - val_loss: 5.7775 - val_accuracy: 0.3283\n",
            "Epoch 80/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.9447 - accuracy: 0.7325 - val_loss: 5.8767 - val_accuracy: 0.3194\n",
            "Epoch 81/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.9302 - accuracy: 0.7359 - val_loss: 6.0762 - val_accuracy: 0.3267\n",
            "Epoch 82/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.9076 - accuracy: 0.7407 - val_loss: 5.8294 - val_accuracy: 0.3322\n",
            "Epoch 83/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.9026 - accuracy: 0.7426 - val_loss: 5.9621 - val_accuracy: 0.3327\n",
            "Epoch 84/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.8799 - accuracy: 0.7491 - val_loss: 5.9689 - val_accuracy: 0.3321\n",
            "Epoch 85/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.8642 - accuracy: 0.7523 - val_loss: 5.7898 - val_accuracy: 0.3308\n",
            "Epoch 86/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.8470 - accuracy: 0.7566 - val_loss: 6.1933 - val_accuracy: 0.3329\n",
            "Epoch 87/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.8291 - accuracy: 0.7622 - val_loss: 5.9633 - val_accuracy: 0.3363\n",
            "Epoch 88/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.8245 - accuracy: 0.7620 - val_loss: 6.1316 - val_accuracy: 0.3352\n",
            "Epoch 89/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.8121 - accuracy: 0.7663 - val_loss: 6.2246 - val_accuracy: 0.3354\n",
            "Epoch 90/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.7886 - accuracy: 0.7724 - val_loss: 6.2337 - val_accuracy: 0.3354\n",
            "Epoch 91/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.7773 - accuracy: 0.7740 - val_loss: 6.2473 - val_accuracy: 0.3346\n",
            "Epoch 92/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.7651 - accuracy: 0.7789 - val_loss: 6.2200 - val_accuracy: 0.3384\n",
            "Epoch 93/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.7557 - accuracy: 0.7795 - val_loss: 6.3718 - val_accuracy: 0.3369\n",
            "Epoch 94/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.7434 - accuracy: 0.7834 - val_loss: 6.3554 - val_accuracy: 0.3335\n",
            "Epoch 95/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.7317 - accuracy: 0.7860 - val_loss: 6.4507 - val_accuracy: 0.3374\n",
            "Epoch 96/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 0.7195 - accuracy: 0.7897 - val_loss: 6.5141 - val_accuracy: 0.3392\n",
            "Epoch 97/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.7043 - accuracy: 0.7944 - val_loss: 6.4694 - val_accuracy: 0.3383\n",
            "Epoch 98/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6998 - accuracy: 0.7938 - val_loss: 6.4507 - val_accuracy: 0.3381\n",
            "Epoch 99/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6806 - accuracy: 0.7993 - val_loss: 6.3764 - val_accuracy: 0.3394\n",
            "Epoch 100/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6706 - accuracy: 0.8022 - val_loss: 6.8348 - val_accuracy: 0.3384\n",
            "Epoch 101/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6660 - accuracy: 0.8039 - val_loss: 6.6676 - val_accuracy: 0.3404\n",
            "Epoch 102/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6541 - accuracy: 0.8073 - val_loss: 6.7475 - val_accuracy: 0.3428\n",
            "Epoch 103/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6426 - accuracy: 0.8090 - val_loss: 6.8185 - val_accuracy: 0.3402\n",
            "Epoch 104/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6393 - accuracy: 0.8102 - val_loss: 6.7106 - val_accuracy: 0.3444\n",
            "Epoch 105/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6213 - accuracy: 0.8157 - val_loss: 6.8764 - val_accuracy: 0.3414\n",
            "Epoch 106/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6196 - accuracy: 0.8146 - val_loss: 6.9877 - val_accuracy: 0.3418\n",
            "Epoch 107/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.6106 - accuracy: 0.8193 - val_loss: 6.8513 - val_accuracy: 0.3414\n",
            "Epoch 108/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5927 - accuracy: 0.8223 - val_loss: 6.7963 - val_accuracy: 0.3430\n",
            "Epoch 109/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5953 - accuracy: 0.8221 - val_loss: 6.9610 - val_accuracy: 0.3432\n",
            "Epoch 110/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5815 - accuracy: 0.8281 - val_loss: 6.9747 - val_accuracy: 0.3443\n",
            "Epoch 111/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5737 - accuracy: 0.8277 - val_loss: 7.0640 - val_accuracy: 0.3430\n",
            "Epoch 112/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 0.5686 - accuracy: 0.8291 - val_loss: 7.0376 - val_accuracy: 0.3434\n",
            "Epoch 113/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5550 - accuracy: 0.8336 - val_loss: 7.1932 - val_accuracy: 0.3424\n",
            "Epoch 114/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5544 - accuracy: 0.8346 - val_loss: 7.2900 - val_accuracy: 0.3436\n",
            "Epoch 115/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5464 - accuracy: 0.8360 - val_loss: 7.4354 - val_accuracy: 0.3444\n",
            "Epoch 116/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5372 - accuracy: 0.8378 - val_loss: 6.9536 - val_accuracy: 0.3461\n",
            "Epoch 117/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5285 - accuracy: 0.8414 - val_loss: 7.2906 - val_accuracy: 0.3453\n",
            "Epoch 118/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5276 - accuracy: 0.8424 - val_loss: 7.4820 - val_accuracy: 0.3452\n",
            "Epoch 119/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5128 - accuracy: 0.8454 - val_loss: 7.3258 - val_accuracy: 0.3443\n",
            "Epoch 120/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5218 - accuracy: 0.8426 - val_loss: 7.3423 - val_accuracy: 0.3455\n",
            "Epoch 121/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.5068 - accuracy: 0.8471 - val_loss: 7.5471 - val_accuracy: 0.3452\n",
            "Epoch 122/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4993 - accuracy: 0.8498 - val_loss: 7.0731 - val_accuracy: 0.3463\n",
            "Epoch 123/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4975 - accuracy: 0.8508 - val_loss: 7.5763 - val_accuracy: 0.3499\n",
            "Epoch 124/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4939 - accuracy: 0.8533 - val_loss: 7.1974 - val_accuracy: 0.3489\n",
            "Epoch 125/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 0.4806 - accuracy: 0.8545 - val_loss: 7.5271 - val_accuracy: 0.3450\n",
            "Epoch 126/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4769 - accuracy: 0.8560 - val_loss: 7.6865 - val_accuracy: 0.3454\n",
            "Epoch 127/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4817 - accuracy: 0.8561 - val_loss: 7.5555 - val_accuracy: 0.3488\n",
            "Epoch 128/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 0.4658 - accuracy: 0.8599 - val_loss: 7.2254 - val_accuracy: 0.3471\n",
            "Epoch 129/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4722 - accuracy: 0.8573 - val_loss: 7.7248 - val_accuracy: 0.3506\n",
            "Epoch 130/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4653 - accuracy: 0.8601 - val_loss: 7.4886 - val_accuracy: 0.3471\n",
            "Epoch 131/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4547 - accuracy: 0.8630 - val_loss: 7.7710 - val_accuracy: 0.3469\n",
            "Epoch 132/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4483 - accuracy: 0.8635 - val_loss: 7.9722 - val_accuracy: 0.3457\n",
            "Epoch 133/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4421 - accuracy: 0.8659 - val_loss: 7.7178 - val_accuracy: 0.3461\n",
            "Epoch 134/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4476 - accuracy: 0.8632 - val_loss: 7.5690 - val_accuracy: 0.3498\n",
            "Epoch 135/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4390 - accuracy: 0.8665 - val_loss: 7.6438 - val_accuracy: 0.3476\n",
            "Epoch 136/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4272 - accuracy: 0.8702 - val_loss: 7.5729 - val_accuracy: 0.3460\n",
            "Epoch 137/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4369 - accuracy: 0.8687 - val_loss: 7.7079 - val_accuracy: 0.3508\n",
            "Epoch 138/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4233 - accuracy: 0.8721 - val_loss: 7.7092 - val_accuracy: 0.3491\n",
            "Epoch 139/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4281 - accuracy: 0.8712 - val_loss: 7.9524 - val_accuracy: 0.3498\n",
            "Epoch 140/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4199 - accuracy: 0.8729 - val_loss: 7.9848 - val_accuracy: 0.3485\n",
            "Epoch 141/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4186 - accuracy: 0.8731 - val_loss: 7.9368 - val_accuracy: 0.3528\n",
            "Epoch 142/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4232 - accuracy: 0.8730 - val_loss: 7.8135 - val_accuracy: 0.3504\n",
            "Epoch 143/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4073 - accuracy: 0.8762 - val_loss: 8.0002 - val_accuracy: 0.3528\n",
            "Epoch 144/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4018 - accuracy: 0.8781 - val_loss: 7.7044 - val_accuracy: 0.3485\n",
            "Epoch 145/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 0.4011 - accuracy: 0.8791 - val_loss: 8.0869 - val_accuracy: 0.3470\n",
            "Epoch 146/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.4034 - accuracy: 0.8782 - val_loss: 7.9289 - val_accuracy: 0.3477\n",
            "Epoch 147/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3970 - accuracy: 0.8800 - val_loss: 7.7315 - val_accuracy: 0.3532\n",
            "Epoch 148/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3916 - accuracy: 0.8821 - val_loss: 7.9982 - val_accuracy: 0.3544\n",
            "Epoch 149/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3931 - accuracy: 0.8826 - val_loss: 7.8102 - val_accuracy: 0.3510\n",
            "Epoch 150/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3900 - accuracy: 0.8822 - val_loss: 8.0398 - val_accuracy: 0.3531\n",
            "Epoch 151/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3808 - accuracy: 0.8848 - val_loss: 8.1084 - val_accuracy: 0.3510\n",
            "Epoch 152/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3831 - accuracy: 0.8851 - val_loss: 7.8500 - val_accuracy: 0.3503\n",
            "Epoch 153/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3825 - accuracy: 0.8851 - val_loss: 8.1189 - val_accuracy: 0.3512\n",
            "Epoch 154/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3822 - accuracy: 0.8841 - val_loss: 8.2271 - val_accuracy: 0.3518\n",
            "Epoch 155/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3749 - accuracy: 0.8868 - val_loss: 8.1334 - val_accuracy: 0.3519\n",
            "Epoch 156/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3737 - accuracy: 0.8874 - val_loss: 8.3265 - val_accuracy: 0.3505\n",
            "Epoch 157/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3671 - accuracy: 0.8892 - val_loss: 8.2662 - val_accuracy: 0.3510\n",
            "Epoch 158/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3619 - accuracy: 0.8888 - val_loss: 8.1660 - val_accuracy: 0.3522\n",
            "Epoch 159/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3663 - accuracy: 0.8889 - val_loss: 8.1618 - val_accuracy: 0.3531\n",
            "Epoch 160/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3647 - accuracy: 0.8899 - val_loss: 7.9975 - val_accuracy: 0.3552\n",
            "Epoch 161/1000\n",
            "3390/3390 [==============================] - 20s 6ms/step - loss: 0.3645 - accuracy: 0.8893 - val_loss: 8.0472 - val_accuracy: 0.3509\n",
            "Epoch 162/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3524 - accuracy: 0.8935 - val_loss: 8.1041 - val_accuracy: 0.3534\n",
            "Epoch 163/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3532 - accuracy: 0.8930 - val_loss: 8.2525 - val_accuracy: 0.3517\n",
            "Epoch 164/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3521 - accuracy: 0.8925 - val_loss: 8.2984 - val_accuracy: 0.3520\n",
            "Epoch 165/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3474 - accuracy: 0.8947 - val_loss: 8.2193 - val_accuracy: 0.3534\n",
            "Epoch 166/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3504 - accuracy: 0.8945 - val_loss: 8.2823 - val_accuracy: 0.3529\n",
            "Epoch 167/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3468 - accuracy: 0.8949 - val_loss: 8.3276 - val_accuracy: 0.3517\n",
            "Epoch 168/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3414 - accuracy: 0.8974 - val_loss: 8.3590 - val_accuracy: 0.3534\n",
            "Epoch 169/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3477 - accuracy: 0.8950 - val_loss: 8.5257 - val_accuracy: 0.3526\n",
            "Epoch 170/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3381 - accuracy: 0.8966 - val_loss: 8.4707 - val_accuracy: 0.3529\n",
            "Epoch 171/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3360 - accuracy: 0.8981 - val_loss: 8.6753 - val_accuracy: 0.3509\n",
            "Epoch 172/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3340 - accuracy: 0.8987 - val_loss: 8.2580 - val_accuracy: 0.3537\n",
            "Epoch 173/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3314 - accuracy: 0.8992 - val_loss: 8.3465 - val_accuracy: 0.3530\n",
            "Epoch 174/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3240 - accuracy: 0.9009 - val_loss: 8.4438 - val_accuracy: 0.3520\n",
            "Epoch 175/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3301 - accuracy: 0.9000 - val_loss: 8.3507 - val_accuracy: 0.3516\n",
            "Epoch 176/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3297 - accuracy: 0.9003 - val_loss: 8.2242 - val_accuracy: 0.3562\n",
            "Epoch 177/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3302 - accuracy: 0.9000 - val_loss: 8.6902 - val_accuracy: 0.3489\n",
            "Epoch 178/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3235 - accuracy: 0.9022 - val_loss: 8.4526 - val_accuracy: 0.3533\n",
            "Epoch 179/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3249 - accuracy: 0.9012 - val_loss: 8.0774 - val_accuracy: 0.3566\n",
            "Epoch 180/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3220 - accuracy: 0.9032 - val_loss: 8.4945 - val_accuracy: 0.3496\n",
            "Epoch 181/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3214 - accuracy: 0.9026 - val_loss: 8.4110 - val_accuracy: 0.3527\n",
            "Epoch 182/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3175 - accuracy: 0.9042 - val_loss: 8.3989 - val_accuracy: 0.3537\n",
            "Epoch 183/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3116 - accuracy: 0.9059 - val_loss: 8.4365 - val_accuracy: 0.3545\n",
            "Epoch 184/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3106 - accuracy: 0.9063 - val_loss: 8.2462 - val_accuracy: 0.3546\n",
            "Epoch 185/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3105 - accuracy: 0.9060 - val_loss: 8.8205 - val_accuracy: 0.3521\n",
            "Epoch 186/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3119 - accuracy: 0.9054 - val_loss: 8.7429 - val_accuracy: 0.3502\n",
            "Epoch 187/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3053 - accuracy: 0.9068 - val_loss: 8.3827 - val_accuracy: 0.3562\n",
            "Epoch 188/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3148 - accuracy: 0.9052 - val_loss: 8.3912 - val_accuracy: 0.3491\n",
            "Epoch 189/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3024 - accuracy: 0.9084 - val_loss: 8.5338 - val_accuracy: 0.3514\n",
            "Epoch 190/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3073 - accuracy: 0.9064 - val_loss: 8.4058 - val_accuracy: 0.3536\n",
            "Epoch 191/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3007 - accuracy: 0.9097 - val_loss: 8.3772 - val_accuracy: 0.3543\n",
            "Epoch 192/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3122 - accuracy: 0.9078 - val_loss: 8.9829 - val_accuracy: 0.3510\n",
            "Epoch 193/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3020 - accuracy: 0.9082 - val_loss: 8.3982 - val_accuracy: 0.3550\n",
            "Epoch 194/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2951 - accuracy: 0.9106 - val_loss: 8.4178 - val_accuracy: 0.3533\n",
            "Epoch 195/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.3014 - accuracy: 0.9091 - val_loss: 8.9347 - val_accuracy: 0.3533\n",
            "Epoch 196/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2906 - accuracy: 0.9113 - val_loss: 8.8378 - val_accuracy: 0.3542\n",
            "Epoch 197/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2985 - accuracy: 0.9099 - val_loss: 8.6910 - val_accuracy: 0.3518\n",
            "Epoch 198/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2940 - accuracy: 0.9120 - val_loss: 8.7698 - val_accuracy: 0.3557\n",
            "Epoch 199/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2922 - accuracy: 0.9111 - val_loss: 8.6749 - val_accuracy: 0.3560\n",
            "Epoch 200/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2907 - accuracy: 0.9128 - val_loss: 8.7487 - val_accuracy: 0.3540\n",
            "Epoch 201/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2910 - accuracy: 0.9127 - val_loss: 8.8711 - val_accuracy: 0.3546\n",
            "Epoch 202/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2877 - accuracy: 0.9139 - val_loss: 8.8363 - val_accuracy: 0.3526\n",
            "Epoch 203/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2870 - accuracy: 0.9128 - val_loss: 8.5076 - val_accuracy: 0.3565\n",
            "Epoch 204/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2826 - accuracy: 0.9146 - val_loss: 8.4389 - val_accuracy: 0.3548\n",
            "Epoch 205/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2854 - accuracy: 0.9133 - val_loss: 8.3124 - val_accuracy: 0.3569\n",
            "Epoch 206/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2922 - accuracy: 0.9127 - val_loss: 9.0133 - val_accuracy: 0.3543\n",
            "Epoch 207/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2849 - accuracy: 0.9139 - val_loss: 8.6213 - val_accuracy: 0.3573\n",
            "Epoch 208/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2766 - accuracy: 0.9168 - val_loss: 8.8709 - val_accuracy: 0.3565\n",
            "Epoch 209/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2812 - accuracy: 0.9163 - val_loss: 8.6258 - val_accuracy: 0.3565\n",
            "Epoch 210/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2836 - accuracy: 0.9161 - val_loss: 8.6984 - val_accuracy: 0.3539\n",
            "Epoch 211/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2788 - accuracy: 0.9161 - val_loss: 8.3345 - val_accuracy: 0.3541\n",
            "Epoch 212/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2806 - accuracy: 0.9159 - val_loss: 8.9107 - val_accuracy: 0.3545\n",
            "Epoch 213/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2802 - accuracy: 0.9154 - val_loss: 8.7921 - val_accuracy: 0.3531\n",
            "Epoch 214/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2716 - accuracy: 0.9184 - val_loss: 8.6688 - val_accuracy: 0.3553\n",
            "Epoch 215/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2722 - accuracy: 0.9178 - val_loss: 9.0687 - val_accuracy: 0.3531\n",
            "Epoch 216/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2785 - accuracy: 0.9162 - val_loss: 8.4709 - val_accuracy: 0.3537\n",
            "Epoch 217/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2689 - accuracy: 0.9184 - val_loss: 8.7684 - val_accuracy: 0.3554\n",
            "Epoch 218/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2701 - accuracy: 0.9172 - val_loss: 8.3850 - val_accuracy: 0.3561\n",
            "Epoch 219/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2725 - accuracy: 0.9182 - val_loss: 9.3594 - val_accuracy: 0.3543\n",
            "Epoch 220/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2667 - accuracy: 0.9195 - val_loss: 8.9213 - val_accuracy: 0.3548\n",
            "Epoch 221/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2727 - accuracy: 0.9182 - val_loss: 8.8042 - val_accuracy: 0.3558\n",
            "Epoch 222/1000\n",
            "3390/3390 [==============================] - 19s 6ms/step - loss: 0.2603 - accuracy: 0.9215 - val_loss: 8.9406 - val_accuracy: 0.3547\n",
            "Epoch 223/1000\n",
            "3046/3390 [=========================>....] - ETA: 1s - loss: 0.2643 - accuracy: 0.9212"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2eaf4abae12a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m           \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1402\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[1;32m   1403\u001b[0m                 \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1246\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1248\u001b[0;31m       \u001b[0moriginal_spe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m       can_run_full_execution = (\n\u001b[1;32m   1250\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    635\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose = 0) \n",
        "\n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "BVOeCTOot2Bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c033579-0d39-4147-88a3-55130341bc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 9.038081169128418\n",
            "Test accuracy: 0.3522157371044159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def music_maker(seed_vec,num_notes = 200):\n",
        "  new_notes = []\n",
        "  arr = np.zeros(len(seed_vec)+num_notes)\n",
        "  for c,i in enumerate(seed_vec):\n",
        "    arr[c] = i\n",
        "  for i in range(0,num_notes,1):\n",
        "    note = one_hot_decode(model.predict(np.reshape(arr[i:len(arr)-num_notes+i], (1, len(arr[i:len(arr)-num_notes+i]), 1))))[0]\n",
        "    new_notes.append(note)\n",
        "    arr[len(seed_vec)+i] = note\n",
        "    \n",
        " \n",
        "  return new_notes\n"
      ],
      "metadata": {
        "id": "zjWjzlEXui7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_music = music_maker(X_test[0])"
      ],
      "metadata": {
        "id": "JQOj4Geguoz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659e8e19-d921-453a-9fa9-a098db090f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 14ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n",
            "1/1 [==============================] - 0s 15ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_music = int_to_string((X_test[0]).tolist())\n",
        "generated_music = int_to_string(final_music)\n",
        "full_song = true_music + generated_music"
      ],
      "metadata": {
        "id": "IxKE5NVXu6_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_midi(generated_music).write('midi', \"generated_song_2.mid\")\n",
        "to_midi(true_music).write('midi', \"true_song_2.mid\")\n",
        "to_midi(full_song).write('midi', \"full_song_2.mid\")"
      ],
      "metadata": {
        "id": "qqCfHbIPxpPr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "9649c167-6c87-4731-92c7-cafd3e29bd4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'full_song_2.mid'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}